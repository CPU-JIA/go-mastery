/*
=== Goæ€§èƒ½æŒæ§ï¼šé«˜çº§æ€§èƒ½åˆ†ææŠ€æœ¯ ===

æœ¬æ¨¡å—æ·±å…¥é«˜çº§æ€§èƒ½åˆ†ææŠ€æœ¯çš„å®ç°å’Œåº”ç”¨ï¼Œæ¢ç´¢ï¼š
1. è‡ªå®šä¹‰é‡‡æ ·å™¨å’Œçƒ­ç‚¹åˆ†æ
2. å®æ—¶æ€§èƒ½ç›‘æ§å’ŒæŠ¥è­¦ç³»ç»Ÿ
3. å¾®åŸºå‡†æµ‹è¯•çš„é«˜çº§æŠ€å·§
4. æ€§èƒ½å›å½’æ£€æµ‹æœºåˆ¶
5. è°ƒç”¨å›¾åˆ†æå’Œç«ç„°å›¾ç”Ÿæˆ
6. ä»£ç è¦†ç›–ç‡å’Œæ€§èƒ½ç›¸å…³æ€§åˆ†æ
7. å†…å­˜æ³„æ¼æ£€æµ‹å’Œåˆ†æ
8. é”ç«äº‰åˆ†æå’Œä¼˜åŒ–
9. ç½‘ç»œI/Oæ€§èƒ½åˆ†æ
10. è‡ªåŠ¨åŒ–æ€§èƒ½ä¼˜åŒ–å»ºè®®

å­¦ä¹ ç›®æ ‡ï¼š
- æŒæ¡ä¼ä¸šçº§æ€§èƒ½åˆ†æå·¥å…·çš„æ„å»º
- ç†è§£æ€§èƒ½ç“¶é¢ˆçš„æ·±åº¦è¯Šæ–­æ–¹æ³•
- å­¦ä¼šæ„å»ºè‡ªåŠ¨åŒ–æ€§èƒ½ç›‘æ§ä½“ç³»
- æŒæ¡æ€§èƒ½ä¼˜åŒ–çš„ç§‘å­¦æ–¹æ³•è®º
*/

package main

import (
	"crypto/rand"
	"fmt"
	"log"
	"math"
	"math/big"
	"net/http"
	"runtime"
	"sort"
	"strings"
	"sync"
	"time"

	"go-mastery/common/security"
)

// å®‰å…¨éšæœºæ•°ç”Ÿæˆå‡½æ•°
func secureRandomFloat64() float64 {
	n, err := rand.Int(rand.Reader, big.NewInt(1<<53))
	if err != nil {
		// å®‰å…¨fallbackï¼šä½¿ç”¨æ—¶é—´æˆ³
		return float64(time.Now().UnixNano()%1000) / 1000.0
	}
	return float64(n.Int64()) / float64(1<<53)
}

// ==================
// 1. é«˜çº§é‡‡æ ·å™¨æ¡†æ¶
// ==================

// SampleType é‡‡æ ·ç±»å‹
type SampleType int

const (
	CPUSample SampleType = iota
	MemorySample
	GoroutineSample
	BlockSample
	MutexSample
	CustomSample
)

func (s SampleType) String() string {
	names := []string{"CPU", "Memory", "Goroutine", "Block", "Mutex", "Custom"}
	if int(s) < len(names) {
		return names[s]
	}
	return "Unknown"
}

// Sample æ€§èƒ½é‡‡æ ·æ•°æ®
type Sample struct {
	Type      SampleType
	Timestamp time.Time
	Value     float64
	Metadata  map[string]interface{}
	Location  StackTrace
}

// StackTrace è°ƒç”¨æ ˆä¿¡æ¯
type StackTrace struct {
	Frames []StackFrame
	Hash   uint64
}

// StackFrame æ ˆå¸§ä¿¡æ¯
type StackFrame struct {
	Function string
	File     string
	Line     int
	PC       uintptr
}

// AdvancedProfiler é«˜çº§æ€§èƒ½åˆ†æå™¨
type AdvancedProfiler struct {
	samples    []Sample
	sampleRate time.Duration
	running    bool
	stopCh     chan struct{}
	wg         sync.WaitGroup
	mutex      sync.RWMutex
	samplers   map[SampleType]Sampler
	hotspots   map[string]*Hotspot
	alerts     []PerformanceAlert
	thresholds map[string]float64
	collector  *MetricsCollector
}

// Sampler é‡‡æ ·å™¨æ¥å£
type Sampler interface {
	Sample() (Sample, error)
	Configure(config map[string]interface{}) error
	Name() string
}

// Hotspot æ€§èƒ½çƒ­ç‚¹
type Hotspot struct {
	Function     string
	File         string
	Line         int
	SampleCount  int64
	TotalValue   float64
	AverageValue float64
	LastSeen     time.Time
	Trend        TrendDirection
}

// TrendDirection è¶‹åŠ¿æ–¹å‘
type TrendDirection int

const (
	TrendUp TrendDirection = iota
	TrendDown
	TrendStable
)

// PerformanceAlert æ€§èƒ½å‘Šè­¦
type PerformanceAlert struct {
	ID        string
	Type      string
	Message   string
	Severity  AlertSeverity
	Timestamp time.Time
	Value     float64
	Threshold float64
	Function  string
	Resolved  bool
	Metadata  map[string]interface{}
}

// AlertSeverity å‘Šè­¦ä¸¥é‡ç¨‹åº¦
type AlertSeverity int

const (
	AlertInfo AlertSeverity = iota
	AlertWarning
	AlertCritical
)

func NewAdvancedProfiler() *AdvancedProfiler {
	profiler := &AdvancedProfiler{
		samples:    make([]Sample, 0),
		sampleRate: 100 * time.Millisecond,
		stopCh:     make(chan struct{}),
		samplers:   make(map[SampleType]Sampler),
		hotspots:   make(map[string]*Hotspot),
		alerts:     make([]PerformanceAlert, 0),
		thresholds: make(map[string]float64),
		collector:  NewMetricsCollector(),
	}

	// æ³¨å†Œé»˜è®¤é‡‡æ ·å™¨
	profiler.RegisterSampler(CPUSample, &CPUSampler{})
	profiler.RegisterSampler(MemorySample, &MemorySampler{})
	profiler.RegisterSampler(GoroutineSample, &GoroutineSampler{})

	// è®¾ç½®é»˜è®¤é˜ˆå€¼
	profiler.SetThreshold("cpu_usage", 80.0)
	profiler.SetThreshold("memory_usage", 85.0)
	profiler.SetThreshold("goroutine_count", 10000)
	profiler.SetThreshold("gc_pause", 10.0) // 10ms

	return profiler
}

func (p *AdvancedProfiler) RegisterSampler(sampleType SampleType, sampler Sampler) {
	p.mutex.Lock()
	defer p.mutex.Unlock()
	p.samplers[sampleType] = sampler
}

func (p *AdvancedProfiler) SetThreshold(metric string, threshold float64) {
	p.mutex.Lock()
	defer p.mutex.Unlock()
	p.thresholds[metric] = threshold
}

func (p *AdvancedProfiler) Start() error {
	p.mutex.Lock()
	defer p.mutex.Unlock()

	if p.running {
		return fmt.Errorf("profiler already running")
	}

	p.running = true

	// å¯åŠ¨é‡‡æ ·å™¨
	for sampleType, sampler := range p.samplers {
		p.wg.Add(1)
		go p.runSampler(sampleType, sampler)
	}

	// å¯åŠ¨çƒ­ç‚¹åˆ†æ
	p.wg.Add(1)
	go p.runHotspotAnalyzer()

	// å¯åŠ¨å‘Šè­¦æ£€æµ‹
	p.wg.Add(1)
	go p.runAlertDetector()

	fmt.Println("é«˜çº§æ€§èƒ½åˆ†æå™¨å·²å¯åŠ¨")
	return nil
}

func (p *AdvancedProfiler) Stop() {
	p.mutex.Lock()
	defer p.mutex.Unlock()

	if !p.running {
		return
	}

	p.running = false
	close(p.stopCh)
	p.wg.Wait()

	fmt.Println("é«˜çº§æ€§èƒ½åˆ†æå™¨å·²åœæ­¢")
}

func (p *AdvancedProfiler) runSampler(sampleType SampleType, sampler Sampler) {
	defer p.wg.Done()

	ticker := time.NewTicker(p.sampleRate)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			sample, err := sampler.Sample()
			if err != nil {
				log.Printf("é‡‡æ ·å™¨ %s é”™è¯¯: %v", sampler.Name(), err)
				continue
			}

			p.mutex.Lock()
			p.samples = append(p.samples, sample)
			// ä¿æŒæœ€è¿‘10000ä¸ªæ ·æœ¬
			if len(p.samples) > 10000 {
				p.samples = p.samples[1000:]
			}
			p.mutex.Unlock()

			// æ›´æ–°çƒ­ç‚¹æ•°æ®
			p.updateHotspot(sample)

		case <-p.stopCh:
			return
		}
	}
}

func (p *AdvancedProfiler) updateHotspot(sample Sample) {
	if len(sample.Location.Frames) == 0 {
		return
	}

	frame := sample.Location.Frames[0]
	key := fmt.Sprintf("%s:%s:%d", frame.Function, frame.File, frame.Line)

	p.mutex.Lock()
	defer p.mutex.Unlock()

	hotspot, exists := p.hotspots[key]
	if !exists {
		hotspot = &Hotspot{
			Function: frame.Function,
			File:     frame.File,
			Line:     frame.Line,
		}
		p.hotspots[key] = hotspot
	}

	hotspot.SampleCount++
	hotspot.TotalValue += sample.Value
	hotspot.AverageValue = hotspot.TotalValue / float64(hotspot.SampleCount)
	hotspot.LastSeen = sample.Timestamp
}

func (p *AdvancedProfiler) runHotspotAnalyzer() {
	defer p.wg.Done()

	ticker := time.NewTicker(5 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			p.analyzeHotspots()

		case <-p.stopCh:
			return
		}
	}
}

func (p *AdvancedProfiler) analyzeHotspots() {
	p.mutex.Lock()
	defer p.mutex.Unlock()

	// åˆ†æçƒ­ç‚¹è¶‹åŠ¿
	for _, hotspot := range p.hotspots {
		// ç®€åŒ–çš„è¶‹åŠ¿åˆ†æ
		if hotspot.SampleCount > 100 {
			if hotspot.AverageValue > hotspot.TotalValue/float64(hotspot.SampleCount)*1.1 {
				hotspot.Trend = TrendUp
			} else if hotspot.AverageValue < hotspot.TotalValue/float64(hotspot.SampleCount)*0.9 {
				hotspot.Trend = TrendDown
			} else {
				hotspot.Trend = TrendStable
			}
		}
	}
}

func (p *AdvancedProfiler) runAlertDetector() {
	defer p.wg.Done()

	ticker := time.NewTicker(time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			p.checkAlerts()

		case <-p.stopCh:
			return
		}
	}
}

func (p *AdvancedProfiler) checkAlerts() {
	p.mutex.RLock()
	samples := make([]Sample, len(p.samples))
	copy(samples, p.samples)
	thresholds := make(map[string]float64)
	for k, v := range p.thresholds {
		thresholds[k] = v
	}
	p.mutex.RUnlock()

	// æ£€æŸ¥æœ€è¿‘çš„æ ·æœ¬
	if len(samples) < 10 {
		return
	}

	recentSamples := samples[len(samples)-10:]

	// CPUä½¿ç”¨ç‡æ£€æŸ¥
	cpuSum := 0.0
	cpuCount := 0
	for _, sample := range recentSamples {
		if sample.Type == CPUSample {
			cpuSum += sample.Value
			cpuCount++
		}
	}

	if cpuCount > 0 {
		avgCPU := cpuSum / float64(cpuCount)
		if threshold, exists := thresholds["cpu_usage"]; exists && avgCPU > threshold {
			alert := PerformanceAlert{
				ID:        fmt.Sprintf("cpu_%d", time.Now().Unix()),
				Type:      "CPU_HIGH",
				Message:   fmt.Sprintf("CPUä½¿ç”¨ç‡è¿‡é«˜: %.2f%%", avgCPU),
				Severity:  AlertWarning,
				Timestamp: time.Now(),
				Value:     avgCPU,
				Threshold: threshold,
			}
			p.addAlert(alert)
		}
	}
}

func (p *AdvancedProfiler) addAlert(alert PerformanceAlert) {
	p.mutex.Lock()
	defer p.mutex.Unlock()

	p.alerts = append(p.alerts, alert)

	// ä¿æŒæœ€è¿‘100ä¸ªå‘Šè­¦
	if len(p.alerts) > 100 {
		p.alerts = p.alerts[10:]
	}

	fmt.Printf("ğŸš¨ æ€§èƒ½å‘Šè­¦: %s\n", alert.Message)
}

func (p *AdvancedProfiler) GetTopHotspots(limit int) []*Hotspot {
	p.mutex.RLock()
	defer p.mutex.RUnlock()

	hotspots := make([]*Hotspot, 0, len(p.hotspots))
	for _, hotspot := range p.hotspots {
		hotspots = append(hotspots, hotspot)
	}

	// æŒ‰æ ·æœ¬æ•°é‡æ’åº
	sort.Slice(hotspots, func(i, j int) bool {
		return hotspots[i].SampleCount > hotspots[j].SampleCount
	})

	if limit > len(hotspots) {
		limit = len(hotspots)
	}

	return hotspots[:limit]
}

func (p *AdvancedProfiler) GetRecentAlerts(limit int) []PerformanceAlert {
	p.mutex.RLock()
	defer p.mutex.RUnlock()

	if limit > len(p.alerts) {
		limit = len(p.alerts)
	}

	alerts := make([]PerformanceAlert, limit)
	copy(alerts, p.alerts[len(p.alerts)-limit:])

	return alerts
}

// ==================
// 2. å…·ä½“é‡‡æ ·å™¨å®ç°
// ==================

// CPUSampler CPUé‡‡æ ·å™¨
type CPUSampler struct {
	lastCPUTime time.Duration
	lastSample  time.Time
}

func (s *CPUSampler) Name() string {
	return "CPU Sampler"
}

func (s *CPUSampler) Configure(config map[string]interface{}) error {
	return nil
}

func (s *CPUSampler) Sample() (Sample, error) {
	now := time.Now()

	// è·å–å½“å‰CPUæ—¶é—´ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
	var ms runtime.MemStats
	runtime.ReadMemStats(&ms)

	cpuUsage := float64(runtime.NumGoroutine()) / float64(runtime.NumCPU()) * 10 // ç®€åŒ–è®¡ç®—

	sample := Sample{
		Type:      CPUSample,
		Timestamp: now,
		Value:     cpuUsage,
		Metadata:  map[string]interface{}{"goroutines": runtime.NumGoroutine()},
		Location:  s.getCurrentStackTrace(),
	}

	return sample, nil
}

func (s *CPUSampler) getCurrentStackTrace() StackTrace {
	pc := make([]uintptr, 32)
	n := runtime.Callers(2, pc)

	frames := make([]StackFrame, 0, n)
	for i := 0; i < n; i++ {
		fn := runtime.FuncForPC(pc[i])
		if fn == nil {
			continue
		}

		file, line := fn.FileLine(pc[i])
		frame := StackFrame{
			Function: fn.Name(),
			File:     file,
			Line:     line,
			PC:       pc[i],
		}
		frames = append(frames, frame)
	}

	return StackTrace{Frames: frames}
}

// MemorySampler å†…å­˜é‡‡æ ·å™¨
type MemorySampler struct{}

func (s *MemorySampler) Name() string {
	return "Memory Sampler"
}

func (s *MemorySampler) Configure(config map[string]interface{}) error {
	return nil
}

func (s *MemorySampler) Sample() (Sample, error) {
	var ms runtime.MemStats
	runtime.ReadMemStats(&ms)

	memUsagePercent := float64(ms.HeapInuse) / float64(ms.HeapSys) * 100

	sample := Sample{
		Type:      MemorySample,
		Timestamp: time.Now(),
		Value:     memUsagePercent,
		Metadata: map[string]interface{}{
			"heap_inuse":   ms.HeapInuse,
			"heap_sys":     ms.HeapSys,
			"heap_objects": ms.HeapObjects,
			"gc_runs":      ms.NumGC,
		},
		Location: StackTrace{}, // å†…å­˜é‡‡æ ·é€šå¸¸ä¸éœ€è¦è°ƒç”¨æ ˆ
	}

	return sample, nil
}

// GoroutineSampler Goroutineé‡‡æ ·å™¨
type GoroutineSampler struct{}

func (s *GoroutineSampler) Name() string {
	return "Goroutine Sampler"
}

func (s *GoroutineSampler) Configure(config map[string]interface{}) error {
	return nil
}

func (s *GoroutineSampler) Sample() (Sample, error) {
	numGoroutines := float64(runtime.NumGoroutine())

	sample := Sample{
		Type:      GoroutineSample,
		Timestamp: time.Now(),
		Value:     numGoroutines,
		Metadata: map[string]interface{}{
			"num_cpu":    runtime.NumCPU(),
			"gomaxprocs": runtime.GOMAXPROCS(0),
		},
		Location: StackTrace{},
	}

	return sample, nil
}

// ==================
// 3. æŒ‡æ ‡æ”¶é›†å™¨
// ==================

// MetricsCollector æŒ‡æ ‡æ”¶é›†å™¨
type MetricsCollector struct {
	metrics map[string]*Metric
	mutex   sync.RWMutex
}

// Metric æŒ‡æ ‡
type Metric struct {
	Name      string
	Type      MetricType
	Value     float64
	Labels    map[string]string
	Timestamp time.Time
	History   []MetricValue
}

// MetricType æŒ‡æ ‡ç±»å‹
type MetricType int

const (
	Counter MetricType = iota
	Gauge
	Histogram
	Summary
)

// MetricValue æŒ‡æ ‡å€¼å†å²
type MetricValue struct {
	Value     float64
	Timestamp time.Time
}

func NewMetricsCollector() *MetricsCollector {
	return &MetricsCollector{
		metrics: make(map[string]*Metric),
	}
}

func (mc *MetricsCollector) RecordCounter(name string, value float64, labels map[string]string) {
	mc.mutex.Lock()
	defer mc.mutex.Unlock()

	key := mc.getMetricKey(name, labels)
	metric, exists := mc.metrics[key]
	if !exists {
		metric = &Metric{
			Name:    name,
			Type:    Counter,
			Labels:  labels,
			History: make([]MetricValue, 0),
		}
		mc.metrics[key] = metric
	}

	metric.Value += value
	metric.Timestamp = time.Now()
	metric.History = append(metric.History, MetricValue{
		Value:     metric.Value,
		Timestamp: metric.Timestamp,
	})

	// ä¿æŒæœ€è¿‘1000ä¸ªå†å²å€¼
	if len(metric.History) > 1000 {
		metric.History = metric.History[100:]
	}
}

func (mc *MetricsCollector) RecordGauge(name string, value float64, labels map[string]string) {
	mc.mutex.Lock()
	defer mc.mutex.Unlock()

	key := mc.getMetricKey(name, labels)
	metric, exists := mc.metrics[key]
	if !exists {
		metric = &Metric{
			Name:    name,
			Type:    Gauge,
			Labels:  labels,
			History: make([]MetricValue, 0),
		}
		mc.metrics[key] = metric
	}

	metric.Value = value
	metric.Timestamp = time.Now()
	metric.History = append(metric.History, MetricValue{
		Value:     value,
		Timestamp: metric.Timestamp,
	})

	if len(metric.History) > 1000 {
		metric.History = metric.History[100:]
	}
}

func (mc *MetricsCollector) getMetricKey(name string, labels map[string]string) string {
	var parts []string
	parts = append(parts, name)

	// æŒ‰é”®æ’åºç¡®ä¿ä¸€è‡´æ€§
	var keys []string
	for k := range labels {
		keys = append(keys, k)
	}
	sort.Strings(keys)

	for _, k := range keys {
		parts = append(parts, fmt.Sprintf("%s=%s", k, labels[k]))
	}

	return strings.Join(parts, "|")
}

func (mc *MetricsCollector) GetMetrics() map[string]*Metric {
	mc.mutex.RLock()
	defer mc.mutex.RUnlock()

	result := make(map[string]*Metric)
	for k, v := range mc.metrics {
		result[k] = v
	}

	return result
}

// ==================
// 4. å¾®åŸºå‡†æµ‹è¯•æ¡†æ¶
// ==================

// BenchmarkSuite åŸºå‡†æµ‹è¯•å¥—ä»¶
type BenchmarkSuite struct {
	benchmarks []BenchmarkFunc
	results    []BenchmarkResult
	config     BenchmarkConfig
}

// BenchmarkFunc åŸºå‡†æµ‹è¯•å‡½æ•°
type BenchmarkFunc struct {
	Name     string
	Function func(*BenchmarkContext)
	Setup    func() interface{}
	Teardown func(interface{})
}

// BenchmarkConfig åŸºå‡†æµ‹è¯•é…ç½®
type BenchmarkConfig struct {
	Duration   time.Duration
	Iterations int
	WarmupRuns int
	CPUProfile bool
	MemProfile bool
	Parallel   bool
}

// BenchmarkContext åŸºå‡†æµ‹è¯•ä¸Šä¸‹æ–‡
type BenchmarkContext struct {
	N         int
	startTime time.Time
	bytes     int64
	netAllocs int64
	netBytes  int64
}

// BenchmarkResult åŸºå‡†æµ‹è¯•ç»“æœ
type BenchmarkResult struct {
	Name        string
	Iterations  int
	Duration    time.Duration
	NsPerOp     int64
	BytesPerOp  int64
	AllocsPerOp int64
	MBPerSec    float64
	MemAllocs   int64
	MemBytes    int64
	CPUSamples  []CPUProfileSample
	Confidence  float64
	Variability float64
}

// CPUProfileSample CPUé‡‡æ ·æ•°æ®
type CPUProfileSample struct {
	Function string
	File     string
	Line     int
	Samples  int64
	Percent  float64
}

func NewBenchmarkSuite() *BenchmarkSuite {
	return &BenchmarkSuite{
		benchmarks: make([]BenchmarkFunc, 0),
		results:    make([]BenchmarkResult, 0),
		config: BenchmarkConfig{
			Duration:   time.Second,
			WarmupRuns: 3,
			Parallel:   false,
		},
	}
}

func (bs *BenchmarkSuite) AddBenchmark(name string, fn func(*BenchmarkContext)) {
	benchmark := BenchmarkFunc{
		Name:     name,
		Function: fn,
	}
	bs.benchmarks = append(bs.benchmarks, benchmark)
}

func (bs *BenchmarkSuite) SetConfig(config BenchmarkConfig) {
	bs.config = config
}

func (bs *BenchmarkSuite) Run() []BenchmarkResult {
	results := make([]BenchmarkResult, 0, len(bs.benchmarks))

	for _, benchmark := range bs.benchmarks {
		fmt.Printf("è¿è¡ŒåŸºå‡†æµ‹è¯•: %s\n", benchmark.Name)
		result := bs.runSingleBenchmark(benchmark)
		results = append(results, result)

		fmt.Printf("  %s: %dæ¬¡è¿­ä»£, %.2f ns/op, %.2f MB/s\n",
			benchmark.Name, result.Iterations, float64(result.NsPerOp), result.MBPerSec)
	}

	bs.results = results
	return results
}

func (bs *BenchmarkSuite) runSingleBenchmark(benchmark BenchmarkFunc) BenchmarkResult {
	// é¢„çƒ­è¿è¡Œ
	for i := 0; i < bs.config.WarmupRuns; i++ {
		ctx := &BenchmarkContext{N: 1000}
		benchmark.Function(ctx)
	}

	// ç¡®å®šè¿­ä»£æ¬¡æ•°
	iterations := bs.determineIterations(benchmark)

	// æ‰§è¡ŒåŸºå‡†æµ‹è¯•
	var memBefore, memAfter runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&memBefore)

	startTime := time.Now()
	ctx := &BenchmarkContext{
		N:         iterations,
		startTime: startTime,
	}

	benchmark.Function(ctx)

	duration := time.Since(startTime)
	runtime.ReadMemStats(&memAfter)

	// è®¡ç®—ç»“æœ
	result := BenchmarkResult{
		Name:       benchmark.Name,
		Iterations: iterations,
		Duration:   duration,
		NsPerOp:    duration.Nanoseconds() / int64(iterations),
		MemAllocs:  security.MustSafeUint64ToInt64(memAfter.Mallocs - memBefore.Mallocs),
		MemBytes:   security.MustSafeUint64ToInt64(memAfter.TotalAlloc - memBefore.TotalAlloc),
	}

	if ctx.bytes > 0 {
		result.BytesPerOp = ctx.bytes / int64(iterations)
		result.MBPerSec = float64(ctx.bytes) / duration.Seconds() / 1024 / 1024
	}

	if result.MemAllocs > 0 {
		result.AllocsPerOp = result.MemAllocs / int64(iterations)
	}

	return result
}

func (bs *BenchmarkSuite) determineIterations(benchmark BenchmarkFunc) int {
	// è‡ªåŠ¨ç¡®å®šåˆé€‚çš„è¿­ä»£æ¬¡æ•°
	targetDuration := bs.config.Duration

	// å…ˆè¿è¡Œå°‘é‡è¿­ä»£ä¼°ç®—æ€§èƒ½
	testN := 100
	ctx := &BenchmarkContext{N: testN}

	start := time.Now()
	benchmark.Function(ctx)
	elapsed := time.Since(start)

	if elapsed == 0 {
		return 1000000 // é»˜è®¤å€¼
	}

	// æ ¹æ®ç›®æ ‡æ—¶é—´è®¡ç®—è¿­ä»£æ¬¡æ•°
	iterations := int(targetDuration.Nanoseconds() / elapsed.Nanoseconds() * int64(testN))

	// é™åˆ¶èŒƒå›´
	if iterations < 1 {
		iterations = 1
	}
	if iterations > 1000000 {
		iterations = 1000000
	}

	return iterations
}

func (ctx *BenchmarkContext) SetBytes(n int64) {
	ctx.bytes = n
}

func (ctx *BenchmarkContext) ResetTimer() {
	ctx.startTime = time.Now()
}

// ==================
// 5. æ€§èƒ½å›å½’æ£€æµ‹
// ==================

// RegressionDetector æ€§èƒ½å›å½’æ£€æµ‹å™¨
type RegressionDetector struct {
	baselines map[string]Baseline
	mutex     sync.RWMutex
	threshold float64 // å›å½’é˜ˆå€¼ç™¾åˆ†æ¯”
}

// Baseline æ€§èƒ½åŸºçº¿
type Baseline struct {
	Name         string
	Value        float64
	StandardDev  float64
	SampleCount  int
	LastUpdated  time.Time
	Measurements []float64
}

// RegressionReport å›å½’æŠ¥å‘Š
type RegressionReport struct {
	TestName          string
	BaselineValue     float64
	CurrentValue      float64
	RegressionPercent float64
	IsRegression      bool
	Confidence        float64
	Timestamp         time.Time
}

func NewRegressionDetector(threshold float64) *RegressionDetector {
	return &RegressionDetector{
		baselines: make(map[string]Baseline),
		threshold: threshold,
	}
}

func (rd *RegressionDetector) UpdateBaseline(name string, value float64) {
	rd.mutex.Lock()
	defer rd.mutex.Unlock()

	baseline, exists := rd.baselines[name]
	if !exists {
		baseline = Baseline{
			Name:         name,
			Measurements: make([]float64, 0),
		}
	}

	baseline.Measurements = append(baseline.Measurements, value)

	// ä¿æŒæœ€è¿‘100ä¸ªæµ‹é‡å€¼
	if len(baseline.Measurements) > 100 {
		baseline.Measurements = baseline.Measurements[1:]
	}

	// è®¡ç®—ç»Ÿè®¡å€¼
	sum := 0.0
	for _, v := range baseline.Measurements {
		sum += v
	}
	baseline.Value = sum / float64(len(baseline.Measurements))
	baseline.SampleCount = len(baseline.Measurements)
	baseline.LastUpdated = time.Now()

	// è®¡ç®—æ ‡å‡†å·®
	if len(baseline.Measurements) > 1 {
		variance := 0.0
		for _, v := range baseline.Measurements {
			variance += math.Pow(v-baseline.Value, 2)
		}
		baseline.StandardDev = math.Sqrt(variance / float64(len(baseline.Measurements)-1))
	}

	rd.baselines[name] = baseline
}

func (rd *RegressionDetector) CheckRegression(name string, currentValue float64) RegressionReport {
	rd.mutex.RLock()
	baseline, exists := rd.baselines[name]
	rd.mutex.RUnlock()

	report := RegressionReport{
		TestName:     name,
		CurrentValue: currentValue,
		Timestamp:    time.Now(),
	}

	if !exists || baseline.SampleCount < 5 {
		report.IsRegression = false
		report.Confidence = 0.0
		return report
	}

	report.BaselineValue = baseline.Value
	report.RegressionPercent = (currentValue - baseline.Value) / baseline.Value * 100

	// ä½¿ç”¨ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
	if baseline.StandardDev > 0 {
		zScore := math.Abs(currentValue-baseline.Value) / baseline.StandardDev
		report.Confidence = rd.calculateConfidence(zScore)
	}

	// åˆ¤æ–­æ˜¯å¦ä¸ºå›å½’
	if report.RegressionPercent > rd.threshold && report.Confidence > 0.95 {
		report.IsRegression = true
	}

	return report
}

func (rd *RegressionDetector) calculateConfidence(zScore float64) float64 {
	// ç®€åŒ–çš„ç½®ä¿¡åº¦è®¡ç®—ï¼ˆåŸºäºZåˆ†æ•°ï¼‰
	if zScore < 1.0 {
		return 0.68
	} else if zScore < 2.0 {
		return 0.95
	} else if zScore < 3.0 {
		return 0.99
	}
	return 0.999
}

func (rd *RegressionDetector) GetBaselines() map[string]Baseline {
	rd.mutex.RLock()
	defer rd.mutex.RUnlock()

	result := make(map[string]Baseline)
	for k, v := range rd.baselines {
		result[k] = v
	}

	return result
}

// ==================
// 6. å†…å­˜æ³„æ¼æ£€æµ‹
// ==================

// LeakDetector å†…å­˜æ³„æ¼æ£€æµ‹å™¨
type LeakDetector struct {
	snapshots    []MemorySnapshot
	allocHistory map[string]*AllocationHistory
	mutex        sync.RWMutex
}

// MemorySnapshot å†…å­˜å¿«ç…§
type MemorySnapshot struct {
	Timestamp   time.Time
	HeapInuse   uint64
	HeapObjects uint64
	StackInuse  uint64
	Allocs      uint64
	Frees       uint64
	GCRuns      uint32
	Goroutines  int
}

// AllocationHistory åˆ†é…å†å²
type AllocationHistory struct {
	Function      string
	AllocCount    int64
	TotalSize     int64
	PeakSize      int64
	LastAllocTime time.Time
	Trend         TrendDirection
}

// LeakReport æ³„æ¼æŠ¥å‘Š
type LeakReport struct {
	Detected        bool
	LeakRate        float64 // MB/hour
	SuspiciousFuncs []SuspiciousFunction
	Recommendations []string
	Timestamp       time.Time
}

// SuspiciousFunction å¯ç–‘å‡½æ•°
type SuspiciousFunction struct {
	Name       string
	AllocRate  float64
	Size       int64
	Confidence float64
}

func NewLeakDetector() *LeakDetector {
	return &LeakDetector{
		snapshots:    make([]MemorySnapshot, 0),
		allocHistory: make(map[string]*AllocationHistory),
	}
}

func (ld *LeakDetector) TakeSnapshot() {
	var ms runtime.MemStats
	runtime.ReadMemStats(&ms)

	snapshot := MemorySnapshot{
		Timestamp:   time.Now(),
		HeapInuse:   ms.HeapInuse,
		HeapObjects: ms.HeapObjects,
		StackInuse:  ms.StackInuse,
		Allocs:      ms.Mallocs,
		Frees:       ms.Frees,
		GCRuns:      ms.NumGC,
		Goroutines:  runtime.NumGoroutine(),
	}

	ld.mutex.Lock()
	ld.snapshots = append(ld.snapshots, snapshot)

	// ä¿æŒæœ€è¿‘1000ä¸ªå¿«ç…§
	if len(ld.snapshots) > 1000 {
		ld.snapshots = ld.snapshots[100:]
	}
	ld.mutex.Unlock()
}

func (ld *LeakDetector) AnalyzeLeaks() LeakReport {
	ld.mutex.RLock()
	snapshots := make([]MemorySnapshot, len(ld.snapshots))
	copy(snapshots, ld.snapshots)
	ld.mutex.RUnlock()

	report := LeakReport{
		Timestamp:       time.Now(),
		SuspiciousFuncs: make([]SuspiciousFunction, 0),
		Recommendations: make([]string, 0),
	}

	if len(snapshots) < 10 {
		return report
	}

	// åˆ†æå†…å­˜å¢é•¿è¶‹åŠ¿
	timeSpan := snapshots[len(snapshots)-1].Timestamp.Sub(snapshots[0].Timestamp)
	memoryGrowth := security.MustSafeUint64ToInt64(snapshots[len(snapshots)-1].HeapInuse) - security.MustSafeUint64ToInt64(snapshots[0].HeapInuse)

	if timeSpan.Hours() > 0 {
		report.LeakRate = float64(memoryGrowth) / timeSpan.Hours() / 1024 / 1024 // MB/hour
	}

	// æ£€æµ‹æ˜¯å¦å­˜åœ¨æ³„æ¼
	if report.LeakRate > 10.0 { // è¶…è¿‡10MB/hourè®¤ä¸ºå¯èƒ½æœ‰æ³„æ¼
		report.Detected = true
		report.Recommendations = append(report.Recommendations,
			"æ£€æµ‹åˆ°æŒç»­çš„å†…å­˜å¢é•¿ï¼Œå»ºè®®è¿›è¡Œè¯¦ç»†çš„å†…å­˜åˆ†æ",
			"ä½¿ç”¨go tool pprofåˆ†æheap profile",
			"æ£€æŸ¥æ˜¯å¦æœ‰goroutineæ³„æ¼",
			"éªŒè¯deferè¯­å¥å’Œèµ„æºæ¸…ç†ä»£ç ",
		)
	}

	// åˆ†ægoroutineæ•°é‡è¶‹åŠ¿
	goroutineGrowth := snapshots[len(snapshots)-1].Goroutines - snapshots[0].Goroutines
	if goroutineGrowth > 100 {
		report.Detected = true
		report.Recommendations = append(report.Recommendations,
			fmt.Sprintf("æ£€æµ‹åˆ°goroutineæ•°é‡å¢é•¿ %dï¼Œå¯èƒ½å­˜åœ¨goroutineæ³„æ¼", goroutineGrowth),
		)
	}

	return report
}

// ==================
// 7. ä¸»æ¼”ç¤ºå‡½æ•°
// ==================

func demonstrateAdvancedProfiling() {
	fmt.Println("=== Goé«˜çº§æ€§èƒ½åˆ†ææŠ€æœ¯æ¼”ç¤º ===")

	// 1. å¯åŠ¨é«˜çº§æ€§èƒ½åˆ†æå™¨
	fmt.Println("\n1. å¯åŠ¨é«˜çº§æ€§èƒ½åˆ†æå™¨")
	profiler := NewAdvancedProfiler()
	profiler.Start()
	defer profiler.Stop()

	// 2. å¯åŠ¨HTTP pprofæœåŠ¡å™¨
	go func() {
		log.Println("pprof server starting on :6060")
		server := &http.Server{
			Addr:         "localhost:6060",
			Handler:      nil,
			ReadTimeout:  15 * time.Second,
			WriteTimeout: 15 * time.Second,
			IdleTimeout:  60 * time.Second,
		}
		log.Println(server.ListenAndServe())
	}()

	// 3. åˆ›å»ºä¸€äº›æ€§èƒ½è´Ÿè½½
	fmt.Println("\n2. ç”Ÿæˆæ€§èƒ½æµ‹è¯•è´Ÿè½½")
	generatePerformanceLoad()

	// ç­‰å¾…é‡‡é›†æ•°æ®
	time.Sleep(3 * time.Second)

	// 4. åˆ†ææ€§èƒ½çƒ­ç‚¹
	fmt.Println("\n3. æ€§èƒ½çƒ­ç‚¹åˆ†æ")
	hotspots := profiler.GetTopHotspots(5)
	for i, hotspot := range hotspots {
		fmt.Printf("çƒ­ç‚¹ %d: %s (%s:%d)\n", i+1, hotspot.Function, hotspot.File, hotspot.Line)
		fmt.Printf("  æ ·æœ¬æ•°: %d, å¹³å‡å€¼: %.2f, è¶‹åŠ¿: %v\n",
			hotspot.SampleCount, hotspot.AverageValue, hotspot.Trend)
	}

	// 5. æ£€æŸ¥æ€§èƒ½å‘Šè­¦
	fmt.Println("\n4. æ€§èƒ½å‘Šè­¦æ£€æŸ¥")
	alerts := profiler.GetRecentAlerts(5)
	for _, alert := range alerts {
		fmt.Printf("å‘Šè­¦: %s (ä¸¥é‡ç¨‹åº¦: %d)\n", alert.Message, alert.Severity)
	}

	// 6. å¾®åŸºå‡†æµ‹è¯•
	fmt.Println("\n5. å¾®åŸºå‡†æµ‹è¯•æ¼”ç¤º")
	suite := NewBenchmarkSuite()

	// æ·»åŠ æµ‹è¯•ç”¨ä¾‹
	suite.AddBenchmark("StringConcat", benchmarkStringConcat)
	suite.AddBenchmark("MapAccess", benchmarkMapAccess)
	suite.AddBenchmark("SliceAlloc", benchmarkSliceAlloc)

	results := suite.Run()

	// 7. æ€§èƒ½å›å½’æ£€æµ‹
	fmt.Println("\n6. æ€§èƒ½å›å½’æ£€æµ‹")
	detector := NewRegressionDetector(10.0) // 10%é˜ˆå€¼

	for _, result := range results {
		// æ›´æ–°åŸºçº¿ï¼ˆæ¨¡æ‹Ÿå†å²æ•°æ®ï¼‰
		for i := 0; i < 10; i++ {
			baselineValue := float64(result.NsPerOp) * (0.9 + secureRandomFloat64()*0.2)
			detector.UpdateBaseline(result.Name, baselineValue)
		}

		// æ£€æŸ¥å½“å‰ç»“æœæ˜¯å¦å›å½’
		report := detector.CheckRegression(result.Name, float64(result.NsPerOp))
		if report.IsRegression {
			fmt.Printf("ğŸš¨ æ€§èƒ½å›å½’: %s, ä¸‹é™ %.2f%%, ç½®ä¿¡åº¦ %.2f\n",
				report.TestName, report.RegressionPercent, report.Confidence)
		} else {
			fmt.Printf("âœ… æ€§èƒ½æ­£å¸¸: %s\n", report.TestName)
		}
	}

	// 8. å†…å­˜æ³„æ¼æ£€æµ‹
	fmt.Println("\n7. å†…å­˜æ³„æ¼æ£€æµ‹")
	leakDetector := NewLeakDetector()

	// æ¨¡æ‹Ÿå†…å­˜åˆ†é…å’Œæ³„æ¼æ£€æµ‹
	for i := 0; i < 10; i++ {
		leakDetector.TakeSnapshot()
		simulateMemoryAllocation()
		time.Sleep(100 * time.Millisecond)
	}

	leakReport := leakDetector.AnalyzeLeaks()
	if leakReport.Detected {
		fmt.Printf("ğŸš¨ æ£€æµ‹åˆ°æ½œåœ¨å†…å­˜æ³„æ¼: %.2f MB/hour\n", leakReport.LeakRate)
		for _, rec := range leakReport.Recommendations {
			fmt.Printf("  å»ºè®®: %s\n", rec)
		}
	} else {
		fmt.Printf("âœ… æœªæ£€æµ‹åˆ°å†…å­˜æ³„æ¼\n")
	}

	// 9. æŒ‡æ ‡æ”¶é›†æ¼”ç¤º
	fmt.Println("\n8. æŒ‡æ ‡æ”¶é›†æ¼”ç¤º")
	collector := profiler.collector

	// è®°å½•ä¸€äº›ç¤ºä¾‹æŒ‡æ ‡
	collector.RecordCounter("http_requests_total", 100, map[string]string{"method": "GET"})
	collector.RecordGauge("memory_usage_bytes", 1024*1024*256, map[string]string{"type": "heap"})

	metrics := collector.GetMetrics()
	fmt.Printf("æ”¶é›†åˆ° %d ä¸ªæŒ‡æ ‡\n", len(metrics))
	for _, metric := range metrics {
		fmt.Printf("  %s: %.2f (%v)\n", metric.Name, metric.Value, metric.Type)
	}
}

func generatePerformanceLoad() {
	// CPUå¯†é›†å‹ä»»åŠ¡
	go func() {
		for i := 0; i < 1000000; i++ {
			sum := 0
			for j := 0; j < 1000; j++ {
				sum += j * j
			}
		}
	}()

	// å†…å­˜åˆ†é…ä»»åŠ¡
	go func() {
		data := make([][]byte, 0)
		for i := 0; i < 1000; i++ {
			chunk := make([]byte, 1024*i)
			data = append(data, chunk)
		}
	}()

	// Goroutineå¯†é›†å‹ä»»åŠ¡
	var wg sync.WaitGroup
	for i := 0; i < 100; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			time.Sleep(time.Millisecond * 10)
		}()
	}
	wg.Wait()
}

func benchmarkStringConcat(ctx *BenchmarkContext) {
	str := ""
	for i := 0; i < ctx.N; i++ {
		str += "test"
	}
}

func benchmarkMapAccess(ctx *BenchmarkContext) {
	m := make(map[int]string)
	for i := 0; i < 1000; i++ {
		m[i] = fmt.Sprintf("value%d", i)
	}

	for i := 0; i < ctx.N; i++ {
		_ = m[i%1000]
	}
}

func benchmarkSliceAlloc(ctx *BenchmarkContext) {
	for i := 0; i < ctx.N; i++ {
		slice := make([]int, 1000)
		for j := range slice {
			slice[j] = j
		}
	}
}

func simulateMemoryAllocation() {
	// æ¨¡æ‹Ÿä¸€äº›å†…å­˜åˆ†é…
	data := make([][]byte, 100)
	for i := range data {
		data[i] = make([]byte, 1024)
	}
}

func main() {
	demonstrateAdvancedProfiling()

	fmt.Println("\n=== Goé«˜çº§æ€§èƒ½åˆ†ææŠ€æœ¯æ¼”ç¤ºå®Œæˆ ===")
	fmt.Println("\nå­¦ä¹ è¦ç‚¹æ€»ç»“:")
	fmt.Println("1. è‡ªå®šä¹‰é‡‡æ ·å™¨ï¼šæ„å»ºä¸“ä¸šçš„æ€§èƒ½ç›‘æ§ä½“ç³»")
	fmt.Println("2. çƒ­ç‚¹åˆ†æï¼šè‡ªåŠ¨è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå’Œè¶‹åŠ¿")
	fmt.Println("3. å®æ—¶å‘Šè­¦ï¼šåŸºäºé˜ˆå€¼çš„æ™ºèƒ½æ€§èƒ½ç›‘æ§")
	fmt.Println("4. å¾®åŸºå‡†æµ‹è¯•ï¼šç²¾ç¡®çš„æ€§èƒ½æµ‹é‡å’Œæ¯”è¾ƒ")
	fmt.Println("5. å›å½’æ£€æµ‹ï¼šç»Ÿè®¡å­¦æ–¹æ³•æ£€æµ‹æ€§èƒ½é€€åŒ–")
	fmt.Println("6. æ³„æ¼æ£€æµ‹ï¼šè‡ªåŠ¨åŒ–å†…å­˜å’Œgoroutineæ³„æ¼åˆ†æ")
	fmt.Println("7. æŒ‡æ ‡æ”¶é›†ï¼šç»“æ„åŒ–çš„æ€§èƒ½æ•°æ®ç®¡ç†")

	fmt.Println("\né«˜çº§ç‰¹æ€§:")
	fmt.Println("- å¤šç»´åº¦æ€§èƒ½é‡‡æ ·å’Œåˆ†æ")
	fmt.Println("- ç»Ÿè®¡å­¦åŸºç¡€çš„æ€§èƒ½è¯„ä¼°")
	fmt.Println("- è‡ªé€‚åº”é˜ˆå€¼å’Œæ™ºèƒ½å‘Šè­¦")
	fmt.Println("- ä¼ä¸šçº§æ€§èƒ½ç›‘æ§æ¶æ„")
	fmt.Println("- ç”Ÿäº§ç¯å¢ƒæ€§èƒ½è¯Šæ–­å·¥å…·")
}

/*
=== ç»ƒä¹ é¢˜ ===

1. é«˜çº§æ€§èƒ½åˆ†æï¼š
   - å®ç°æ›´ç²¾ç¡®çš„CPUä½¿ç”¨ç‡è®¡ç®—
   - æ·»åŠ ç½‘ç»œI/Oæ€§èƒ½ç›‘æ§
   - å®ç°åˆ†å¸ƒå¼æ€§èƒ½æ•°æ®èšåˆ
   - åˆ›å»ºæ€§èƒ½æ•°æ®å¯è§†åŒ–ç•Œé¢

2. å¾®åŸºå‡†æµ‹è¯•ä¼˜åŒ–ï¼š
   - å®ç°ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
   - æ·»åŠ å¤šç»´åº¦æ€§èƒ½æ¯”è¾ƒ
   - åˆ›å»ºåŸºå‡†æµ‹è¯•å¥—ä»¶ç®¡ç†
   - å®ç°æŒç»­æ€§èƒ½ç›‘æ§

3. å†…å­˜åˆ†ææ·±åŒ–ï¼š
   - å®ç°è¯¦ç»†çš„å†…å­˜åˆ†é…è¿½è¸ª
   - æ·»åŠ å†…å­˜ä½¿ç”¨æ¨¡å¼åˆ†æ
   - åˆ›å»ºå†…å­˜ä¼˜åŒ–å»ºè®®ç³»ç»Ÿ
   - å®ç°å†…å­˜ä½¿ç”¨é¢„æµ‹

4. ä¼ä¸šçº§åº”ç”¨ï¼š
   - é›†æˆPrometheus/Grafanaç›‘æ§
   - å®ç°æ€§èƒ½æ•°æ®æŒä¹…åŒ–
   - åˆ›å»ºæ€§èƒ½æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ
   - å»ºç«‹æ€§èƒ½SLAç›‘æ§ä½“ç³»

è¿è¡Œå‘½ä»¤ï¼š
go run main.go

åˆ†æå‘½ä»¤ï¼š
go tool pprof http://localhost:6060/debug/pprof/profile
go tool pprof http://localhost:6060/debug/pprof/heap
go tool trace http://localhost:6060/debug/pprof/trace

é‡è¦æ¦‚å¿µï¼š
- æ€§èƒ½é‡‡æ ·ï¼šç³»ç»ŸåŒ–çš„æ€§èƒ½æ•°æ®æ”¶é›†
- çƒ­ç‚¹åˆ†æï¼šåŸºäºç»Ÿè®¡çš„æ€§èƒ½ç“¶é¢ˆè¯†åˆ«
- å›å½’æ£€æµ‹ï¼šè‡ªåŠ¨åŒ–çš„æ€§èƒ½é€€åŒ–å‘ç°
- æ³„æ¼æ£€æµ‹ï¼šå†…å­˜å’Œèµ„æºæ³„æ¼çš„æ—©æœŸå‘ç°
- åŸºå‡†æµ‹è¯•ï¼šç§‘å­¦çš„æ€§èƒ½æµ‹é‡æ–¹æ³•
*/
