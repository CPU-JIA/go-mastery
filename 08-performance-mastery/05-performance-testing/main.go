/*
=== Goæ€§èƒ½æŒæ§ï¼šè‡ªåŠ¨åŒ–æ€§èƒ½æµ‹è¯•æ¡†æ¶ ===

æœ¬æ¨¡å—ä¸“æ³¨äºæ„å»ºä¼ä¸šçº§è‡ªåŠ¨åŒ–æ€§èƒ½æµ‹è¯•ä½“ç³»ï¼Œæ¢ç´¢ï¼š
1. æ€§èƒ½æµ‹è¯•æ¡†æ¶è®¾è®¡å’Œå®ç°
2. åŸºå‡†æµ‹è¯•çš„è‡ªåŠ¨åŒ–æ‰§è¡Œ
3. æ€§èƒ½å›å½’æ£€æµ‹å’ŒCI/CDé›†æˆ
4. è´Ÿè½½æµ‹è¯•å’Œå‹åŠ›æµ‹è¯•å·¥å…·
5. æ€§èƒ½æŠ¥å‘Šå’Œå¯è§†åŒ–ç³»ç»Ÿ
6. A/Bæµ‹è¯•å’Œæ€§èƒ½å¯¹æ¯”åˆ†æ
7. æŒç»­æ€§èƒ½ç›‘æ§å’Œå‘Šè­¦
8. æ€§èƒ½é¢„ç®—ç®¡ç†ç³»ç»Ÿ
9. å¤šç¯å¢ƒæ€§èƒ½æµ‹è¯•åè°ƒ
10. æ€§èƒ½æµ‹è¯•æ•°æ®åˆ†æå’Œæ´å¯Ÿ

å­¦ä¹ ç›®æ ‡ï¼š
- æ„å»ºå®Œæ•´çš„è‡ªåŠ¨åŒ–æ€§èƒ½æµ‹è¯•ä½“ç³»
- æŒæ¡ä¼ä¸šçº§æ€§èƒ½æµ‹è¯•æœ€ä½³å®è·µ
- å®ç°æ€§èƒ½æµ‹è¯•çš„CI/CDé›†æˆ
- å­¦ä¼šæ€§èƒ½æ•°æ®åˆ†æå’Œä¼˜åŒ–å†³ç­–
*/

package main

import (
	"bytes"
	"context"
	"crypto/rand"
	"encoding/json"
	"fmt"
	"io"
	"math"
	"math/big"
	"net/http"
	"runtime"
	"sort"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	"go-mastery/common/security"
)

// å®‰å…¨éšæœºæ•°ç”Ÿæˆå‡½æ•°
func secureRandomInt(max int) int {
	n, err := rand.Int(rand.Reader, big.NewInt(int64(max)))
	if err != nil {
		// G115å®‰å…¨ä¿®å¤ï¼šç¡®ä¿è½¬æ¢ä¸ä¼šæº¢å‡º
		fallback := time.Now().UnixNano() % int64(max)
		if fallback > int64(^uint(0)>>1) {
			fallback = fallback % int64(^uint(0)>>1)
		}
		return int(fallback)
	}
	// G115å®‰å…¨ä¿®å¤ï¼šæ£€æŸ¥int64åˆ°intçš„å®‰å…¨è½¬æ¢
	result := n.Int64()
	if result > int64(^uint(0)>>1) {
		result = result % int64(max)
	}
	return int(result)
}

func secureRandomFloat64() float64 {
	n, err := rand.Int(rand.Reader, big.NewInt(1<<53))
	if err != nil {
		// å®‰å…¨fallbackï¼šä½¿ç”¨æ—¶é—´æˆ³
		return float64(time.Now().UnixNano()%1000) / 1000.0
	}
	return float64(n.Int64()) / float64(1<<53)
}

// ==================
// 1. æ€§èƒ½æµ‹è¯•æ¡†æ¶æ ¸å¿ƒ
// ==================

// PerformanceTestFramework æ€§èƒ½æµ‹è¯•æ¡†æ¶
type PerformanceTestFramework struct {
	testSuites     map[string]*TestSuite
	config         FrameworkConfig
	scheduler      *TestScheduler
	reporter       *PerformanceReporter
	dataCollector  *MetricsCollector
	alertManager   *AlertManager
	cicdIntegrator *CICDIntegrator
	mutex          sync.RWMutex
	running        bool
	stopCh         chan struct{}
}

// FrameworkConfig æ¡†æ¶é…ç½®
type FrameworkConfig struct {
	MaxConcurrentTests  int
	TestTimeout         time.Duration
	RetentionPeriod     time.Duration
	ReportInterval      time.Duration
	AlertThresholds     map[string]float64
	CICDIntegration     bool
	EnvironmentProfiles map[string]EnvironmentConfig
}

// EnvironmentConfig ç¯å¢ƒé…ç½®
type EnvironmentConfig struct {
	Name        string
	BaselineURL string
	TargetURL   string
	Resources   ResourceLimits
	TestData    map[string]interface{}
}

// ResourceLimits èµ„æºé™åˆ¶
type ResourceLimits struct {
	MaxCPU    float64
	MaxMemory int64
	MaxRPS    int
	MaxUsers  int
}

// TestSuite æµ‹è¯•å¥—ä»¶
type TestSuite struct {
	Name        string
	Description string
	Tests       []*PerformanceTest
	Setup       func() error
	Teardown    func() error
	Environment string
	Schedule    TestSchedule
	Enabled     bool
}

// PerformanceTest æ€§èƒ½æµ‹è¯•
type PerformanceTest struct {
	ID             string
	Name           string
	Type           TestType
	Target         TestTarget
	Configuration  TestConfiguration
	Assertions     []PerformanceAssertion
	Dependencies   []string
	Metadata       map[string]interface{}
	LastExecution  *TestExecution
	ExecutionCount int64
	Enabled        bool
}

// TestType æµ‹è¯•ç±»å‹
type TestType int

const (
	BenchmarkTest TestType = iota
	LoadTest
	StressTest
	SpikeTest
	VolumeTest
	EnduranceTest
	RegressionTest
	ComparisonTest
)

func (tt TestType) String() string {
	types := []string{"Benchmark", "Load", "Stress", "Spike", "Volume", "Endurance", "Regression", "Comparison"}
	if int(tt) < len(types) {
		return types[tt]
	}
	return "Unknown"
}

// TestTarget æµ‹è¯•ç›®æ ‡
type TestTarget struct {
	Function   func() error
	Endpoint   string
	Method     string
	Headers    map[string]string
	Body       []byte
	Parameters map[string]interface{}
}

// TestConfiguration æµ‹è¯•é…ç½®
type TestConfiguration struct {
	Duration       time.Duration
	Iterations     int
	Concurrency    int
	RampUpTime     time.Duration
	RampDownTime   time.Duration
	ThinkTime      time.Duration
	Timeout        time.Duration
	WarmupRuns     int
	CooldownTime   time.Duration
	DataVariations []map[string]interface{}
}

// PerformanceAssertion æ€§èƒ½æ–­è¨€
type PerformanceAssertion struct {
	Metric    string
	Operator  ComparisonOperator
	Expected  float64
	Tolerance float64
	Critical  bool
}

// ComparisonOperator æ¯”è¾ƒæ“ä½œç¬¦
type ComparisonOperator int

const (
	LessThan ComparisonOperator = iota
	LessThanOrEqual
	Equal
	GreaterThanOrEqual
	GreaterThan
	NotEqual
	Within
)

// TestExecution æµ‹è¯•æ‰§è¡Œ
type TestExecution struct {
	ID            string
	TestID        string
	StartTime     time.Time
	EndTime       time.Time
	Duration      time.Duration
	Status        ExecutionStatus
	Results       TestResults
	Metrics       ExecutionMetrics
	Errors        []ExecutionError
	Environment   string
	GitCommit     string
	BuildNumber   string
	TriggerSource string
}

// ExecutionStatus æ‰§è¡ŒçŠ¶æ€
type ExecutionStatus int

const (
	StatusPending ExecutionStatus = iota
	StatusRunning
	StatusCompleted
	StatusFailed
	StatusCancelled
	StatusTimeout
)

// TestResults æµ‹è¯•ç»“æœ
type TestResults struct {
	TotalOperations     int64
	SuccessfulOps       int64
	FailedOps           int64
	ResponseTimes       ResponseTimeStats
	Throughput          ThroughputStats
	ResourceUsage       ResourceUsageStats
	ErrorDistribution   map[string]int64
	PercentileLatencies map[string]time.Duration
	CustomMetrics       map[string]float64
}

// ResponseTimeStats å“åº”æ—¶é—´ç»Ÿè®¡
type ResponseTimeStats struct {
	Min    time.Duration
	Max    time.Duration
	Mean   time.Duration
	Median time.Duration
	P90    time.Duration
	P95    time.Duration
	P99    time.Duration
	P999   time.Duration
	StdDev time.Duration
}

// ThroughputStats ååé‡ç»Ÿè®¡
type ThroughputStats struct {
	RequestsPerSecond   float64
	OperationsPerSecond float64
	BytesPerSecond      float64
	PeakThroughput      float64
	MinThroughput       float64
	AverageThroughput   float64
}

// ResourceUsageStats èµ„æºä½¿ç”¨ç»Ÿè®¡
type ResourceUsageStats struct {
	CPUUsage       CPUStats
	MemoryUsage    MemoryStats
	NetworkUsage   NetworkStats
	DiskUsage      DiskStats
	GoroutineCount GoroutineStats
}

// CPUStats CPUç»Ÿè®¡
type CPUStats struct {
	Average    float64
	Peak       float64
	UserTime   time.Duration
	SystemTime time.Duration
	IdleTime   time.Duration
}

// MemoryStats å†…å­˜ç»Ÿè®¡
type MemoryStats struct {
	HeapUsed     int64
	HeapSys      int64
	StackUsed    int64
	GCRuns       int64
	GCPauseTotal time.Duration
	GCPauseMax   time.Duration
	GCPauseMean  time.Duration
	AllocRate    float64
}

// NetworkStats ç½‘ç»œç»Ÿè®¡
type NetworkStats struct {
	BytesSent       int64
	BytesReceived   int64
	PacketsSent     int64
	PacketsReceived int64
	Connections     int64
	Errors          int64
}

// DiskStats ç£ç›˜ç»Ÿè®¡
type DiskStats struct {
	BytesRead    int64
	BytesWritten int64
	IOOperations int64
	IOWaitTime   time.Duration
}

// GoroutineStats Goroutineç»Ÿè®¡
type GoroutineStats struct {
	Count   int
	Peak    int
	Created int64
	Blocked int
	Running int
}

// ExecutionMetrics æ‰§è¡ŒæŒ‡æ ‡
type ExecutionMetrics struct {
	TestOverhead     time.Duration
	SetupTime        time.Duration
	ExecutionTime    time.Duration
	TeardownTime     time.Duration
	DataTransferred  int64
	ConcurrencyLevel int
	ActualIterations int64
	SuccessRate      float64
}

// ExecutionError æ‰§è¡Œé”™è¯¯
type ExecutionError struct {
	Timestamp   time.Time
	Type        string
	Message     string
	StackTrace  string
	Context     map[string]interface{}
	Recoverable bool
}

func NewPerformanceTestFramework(config FrameworkConfig) *PerformanceTestFramework {
	return &PerformanceTestFramework{
		testSuites:     make(map[string]*TestSuite),
		config:         config,
		scheduler:      NewTestScheduler(),
		reporter:       NewPerformanceReporter(),
		dataCollector:  NewMetricsCollector(),
		alertManager:   NewAlertManager(),
		cicdIntegrator: NewCICDIntegrator(),
		stopCh:         make(chan struct{}),
	}
}

func (ptf *PerformanceTestFramework) Start() error {
	ptf.mutex.Lock()
	defer ptf.mutex.Unlock()

	if ptf.running {
		return fmt.Errorf("framework already running")
	}

	ptf.running = true

	// å¯åŠ¨å„ä¸ªç»„ä»¶
	go ptf.scheduler.Run()
	go ptf.dataCollector.Run()
	go ptf.alertManager.Run()

	fmt.Println("æ€§èƒ½æµ‹è¯•æ¡†æ¶å·²å¯åŠ¨")
	return nil
}

func (ptf *PerformanceTestFramework) Stop() {
	ptf.mutex.Lock()
	defer ptf.mutex.Unlock()

	if !ptf.running {
		return
	}

	ptf.running = false
	close(ptf.stopCh)
	fmt.Println("æ€§èƒ½æµ‹è¯•æ¡†æ¶å·²åœæ­¢")
}

func (ptf *PerformanceTestFramework) RegisterTestSuite(suite *TestSuite) {
	ptf.mutex.Lock()
	defer ptf.mutex.Unlock()

	ptf.testSuites[suite.Name] = suite
	ptf.scheduler.ScheduleTestSuite(suite)
	fmt.Printf("æ³¨å†Œæµ‹è¯•å¥—ä»¶: %s (%dä¸ªæµ‹è¯•)\n", suite.Name, len(suite.Tests))
}

// ==================
// 2. æµ‹è¯•è°ƒåº¦å™¨
// ==================

// TestScheduler æµ‹è¯•è°ƒåº¦å™¨
type TestScheduler struct {
	queue         *TestQueue
	executor      *TestExecutor
	runningTests  map[string]*TestExecution
	schedules     map[string]TestSchedule
	maxConcurrent int
	mutex         sync.RWMutex
	stopCh        chan struct{}
}

// TestSchedule æµ‹è¯•è°ƒåº¦
type TestSchedule struct {
	Type     ScheduleType
	Interval time.Duration
	CronExpr string
	Triggers []TriggerCondition
	Enabled  bool
	NextRun  time.Time
}

// ScheduleType è°ƒåº¦ç±»å‹
type ScheduleType int

const (
	OnDemand ScheduleType = iota
	Periodic
	Cron
	Triggered
	Continuous
)

// TriggerCondition è§¦å‘æ¡ä»¶
type TriggerCondition struct {
	Type      TriggerType
	Source    string
	Condition string
	Threshold float64
}

// TriggerType è§¦å‘ç±»å‹
type TriggerType int

const (
	GitCommit TriggerType = iota
	MetricThreshold
	TimeWindow
	ExternalEvent
	DependencyUpdate
)

// TestQueue æµ‹è¯•é˜Ÿåˆ—
type TestQueue struct {
	items    []*QueueItem
	priority map[string]int
	mutex    sync.Mutex
}

// QueueItem é˜Ÿåˆ—é¡¹
type QueueItem struct {
	Test     *PerformanceTest
	Priority int
	AddedAt  time.Time
	Context  map[string]interface{}
}

// TestExecutor æµ‹è¯•æ‰§è¡Œå™¨
type TestExecutor struct {
	workers     chan *Worker
	results     chan *TestExecution
	maxWorkers  int
	activeTests map[string]*TestExecution
	mutex       sync.RWMutex
}

// Worker å·¥ä½œè€…
type Worker struct {
	ID      int
	Busy    bool
	Current *PerformanceTest
	Started time.Time
	Context context.Context
	Cancel  context.CancelFunc
}

func NewTestScheduler() *TestScheduler {
	return &TestScheduler{
		queue:         NewTestQueue(),
		executor:      NewTestExecutor(runtime.NumCPU()),
		runningTests:  make(map[string]*TestExecution),
		schedules:     make(map[string]TestSchedule),
		maxConcurrent: runtime.NumCPU() * 2,
		stopCh:        make(chan struct{}),
	}
}

func NewTestQueue() *TestQueue {
	return &TestQueue{
		items:    make([]*QueueItem, 0),
		priority: make(map[string]int),
	}
}

func NewTestExecutor(maxWorkers int) *TestExecutor {
	return &TestExecutor{
		workers:     make(chan *Worker, maxWorkers),
		results:     make(chan *TestExecution, 100),
		maxWorkers:  maxWorkers,
		activeTests: make(map[string]*TestExecution),
	}
}

func (ts *TestScheduler) Run() {
	ticker := time.NewTicker(time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			ts.processSchedules()
			ts.processQueue()

		case <-ts.stopCh:
			return
		}
	}
}

func (ts *TestScheduler) ScheduleTestSuite(suite *TestSuite) {
	ts.mutex.Lock()
	defer ts.mutex.Unlock()

	ts.schedules[suite.Name] = suite.Schedule

	// å°†æµ‹è¯•æ·»åŠ åˆ°é˜Ÿåˆ—
	for _, test := range suite.Tests {
		if test.Enabled {
			ts.queue.Enqueue(test, 1)
		}
	}
}

func (ts *TestScheduler) processSchedules() {
	ts.mutex.RLock()
	schedules := make(map[string]TestSchedule)
	for k, v := range ts.schedules {
		schedules[k] = v
	}
	ts.mutex.RUnlock()

	now := time.Now()
	for name, schedule := range schedules {
		if schedule.Enabled && now.After(schedule.NextRun) {
			fmt.Printf("è§¦å‘å®šæ—¶æµ‹è¯•: %s\n", name)
			// è§¦å‘æµ‹è¯•æ‰§è¡Œé€»è¾‘
		}
	}
}

func (ts *TestScheduler) processQueue() {
	ts.mutex.Lock()
	defer ts.mutex.Unlock()

	if len(ts.runningTests) >= ts.maxConcurrent {
		return
	}

	item := ts.queue.Dequeue()
	if item == nil {
		return
	}

	// å¯åŠ¨æµ‹è¯•æ‰§è¡Œ
	execution := ts.executor.Execute(item.Test)
	ts.runningTests[execution.ID] = execution
}

func (tq *TestQueue) Enqueue(test *PerformanceTest, priority int) {
	tq.mutex.Lock()
	defer tq.mutex.Unlock()

	item := &QueueItem{
		Test:     test,
		Priority: priority,
		AddedAt:  time.Now(),
	}

	tq.items = append(tq.items, item)
	tq.sortByPriority()
}

func (tq *TestQueue) Dequeue() *QueueItem {
	tq.mutex.Lock()
	defer tq.mutex.Unlock()

	if len(tq.items) == 0 {
		return nil
	}

	item := tq.items[0]
	tq.items = tq.items[1:]
	return item
}

func (tq *TestQueue) sortByPriority() {
	sort.Slice(tq.items, func(i, j int) bool {
		return tq.items[i].Priority > tq.items[j].Priority
	})
}

func (te *TestExecutor) Execute(test *PerformanceTest) *TestExecution {
	execution := &TestExecution{
		ID:        generateExecutionID(),
		TestID:    test.ID,
		StartTime: time.Now(),
		Status:    StatusRunning,
	}

	te.mutex.Lock()
	te.activeTests[execution.ID] = execution
	te.mutex.Unlock()

	go te.runTest(test, execution)
	return execution
}

func (te *TestExecutor) runTest(test *PerformanceTest, execution *TestExecution) {
	defer func() {
		execution.EndTime = time.Now()
		execution.Duration = execution.EndTime.Sub(execution.StartTime)

		te.mutex.Lock()
		delete(te.activeTests, execution.ID)
		te.mutex.Unlock()

		te.results <- execution
	}()

	fmt.Printf("æ‰§è¡Œæ€§èƒ½æµ‹è¯•: %s (ç±»å‹: %s)\n", test.Name, test.Type)

	// æ ¹æ®æµ‹è¯•ç±»å‹æ‰§è¡Œä¸åŒçš„æµ‹è¯•é€»è¾‘
	switch test.Type {
	case BenchmarkTest:
		te.runBenchmarkTest(test, execution)
	case LoadTest:
		te.runLoadTest(test, execution)
	case StressTest:
		te.runStressTest(test, execution)
	case RegressionTest:
		te.runRegressionTest(test, execution)
	default:
		te.runGenericTest(test, execution)
	}

	execution.Status = StatusCompleted
	fmt.Printf("æµ‹è¯•å®Œæˆ: %s (è€—æ—¶: %v)\n", test.Name, execution.Duration)
}

func (te *TestExecutor) runBenchmarkTest(test *PerformanceTest, execution *TestExecution) {
	config := test.Configuration
	var totalDuration time.Duration
	var operations int64
	var errors []ExecutionError

	fmt.Printf("åŸºå‡†æµ‹è¯•: %dæ¬¡è¿­ä»£, %då¹¶å‘\n", config.Iterations, config.Concurrency)

	// é¢„çƒ­
	for i := 0; i < config.WarmupRuns; i++ {
		if test.Target.Function != nil {
			test.Target.Function()
		}
	}

	startTime := time.Now()
	var wg sync.WaitGroup
	semaphore := make(chan struct{}, config.Concurrency)

	for i := 0; i < config.Iterations; i++ {
		wg.Add(1)
		go func(iteration int) {
			defer wg.Done()
			semaphore <- struct{}{}
			defer func() { <-semaphore }()

			opStart := time.Now()
			var err error

			if test.Target.Function != nil {
				err = test.Target.Function()
			} else if test.Target.Endpoint != "" {
				err = te.executeHTTPRequest(test.Target)
			}

			opDuration := time.Since(opStart)
			atomic.AddInt64(&operations, 1)

			if err != nil {
				errors = append(errors, ExecutionError{
					Timestamp: time.Now(),
					Type:      "execution_error",
					Message:   err.Error(),
				})
			}

			// ç´¯åŠ è€—æ—¶ï¼ˆåŸå­æ“ä½œçš„ç®€åŒ–ç‰ˆæœ¬ï¼‰
			totalDuration += opDuration
		}(i)
	}

	wg.Wait()
	endTime := time.Now()

	// è®¡ç®—ç»“æœ
	execution.Results = TestResults{
		TotalOperations: operations,
		SuccessfulOps:   operations - int64(len(errors)),
		FailedOps:       int64(len(errors)),
	}

	if operations > 0 {
		avgDuration := totalDuration / time.Duration(operations)
		execution.Results.ResponseTimes.Mean = avgDuration
		execution.Results.Throughput.OperationsPerSecond = float64(operations) / endTime.Sub(startTime).Seconds()
	}

	execution.Errors = errors
}

func (te *TestExecutor) runLoadTest(test *PerformanceTest, execution *TestExecution) {
	config := test.Configuration
	fmt.Printf("è´Ÿè½½æµ‹è¯•: %væŒç»­æ—¶é—´, %då¹¶å‘\n", config.Duration, config.Concurrency)

	// è´Ÿè½½æµ‹è¯•å®ç°
	var operations int64
	var responseTimes []time.Duration
	var errors []ExecutionError
	var mutex sync.Mutex

	ctx, cancel := context.WithTimeout(context.Background(), config.Duration)
	defer cancel()

	var wg sync.WaitGroup
	semaphore := make(chan struct{}, config.Concurrency)

	startTime := time.Now()

	// å¯åŠ¨å·¥ä½œè€…
	for i := 0; i < config.Concurrency; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			for {
				select {
				case <-ctx.Done():
					return
				case semaphore <- struct{}{}:
					opStart := time.Now()
					var err error

					if test.Target.Function != nil {
						err = test.Target.Function()
					} else if test.Target.Endpoint != "" {
						err = te.executeHTTPRequest(test.Target)
					}

					opDuration := time.Since(opStart)
					atomic.AddInt64(&operations, 1)

					mutex.Lock()
					responseTimes = append(responseTimes, opDuration)
					if err != nil {
						errors = append(errors, ExecutionError{
							Timestamp: time.Now(),
							Type:      "load_test_error",
							Message:   err.Error(),
						})
					}
					mutex.Unlock()

					<-semaphore

					// æ€è€ƒæ—¶é—´
					if config.ThinkTime > 0 {
						time.Sleep(config.ThinkTime)
					}
				}
			}
		}(i)
	}

	wg.Wait()
	endTime := time.Now()

	// è®¡ç®—ç»Ÿè®¡ç»“æœ
	execution.Results = te.calculateTestResults(operations, responseTimes, errors, startTime, endTime)
}

func (te *TestExecutor) runStressTest(test *PerformanceTest, execution *TestExecution) {
	config := test.Configuration
	fmt.Printf("å‹åŠ›æµ‹è¯•: é€æ­¥å¢åŠ è´Ÿè½½åˆ° %d å¹¶å‘\n", config.Concurrency)

	// å‹åŠ›æµ‹è¯•å®ç° - é€æ­¥å¢åŠ è´Ÿè½½
	phases := 5
	concurrencyStep := config.Concurrency / phases
	phaseDuration := config.Duration / time.Duration(phases)

	var totalOps int64
	var allResponseTimes []time.Duration
	var allErrors []ExecutionError
	var mutex sync.Mutex

	for phase := 1; phase <= phases; phase++ {
		currentConcurrency := concurrencyStep * phase
		fmt.Printf("å‹åŠ›æµ‹è¯•é˜¶æ®µ %d: %d å¹¶å‘\n", phase, currentConcurrency)

		ctx, cancel := context.WithTimeout(context.Background(), phaseDuration)
		var wg sync.WaitGroup
		semaphore := make(chan struct{}, currentConcurrency)

		var phaseOps int64
		phaseStart := time.Now()

		for i := 0; i < currentConcurrency; i++ {
			wg.Add(1)
			go func() {
				defer wg.Done()

				for {
					select {
					case <-ctx.Done():
						return
					case semaphore <- struct{}{}:
						opStart := time.Now()
						var err error

						if test.Target.Function != nil {
							err = test.Target.Function()
						}

						opDuration := time.Since(opStart)
						atomic.AddInt64(&phaseOps, 1)

						mutex.Lock()
						allResponseTimes = append(allResponseTimes, opDuration)
						if err != nil {
							allErrors = append(allErrors, ExecutionError{
								Timestamp: time.Now(),
								Type:      "stress_test_error",
								Message:   err.Error(),
							})
						}
						mutex.Unlock()

						<-semaphore
					}
				}
			}()
		}

		wg.Wait()
		cancel()

		phaseEnd := time.Now()
		phaseThroughput := float64(phaseOps) / phaseEnd.Sub(phaseStart).Seconds()
		fmt.Printf("é˜¶æ®µ %d å®Œæˆ: %d æ“ä½œ, %.2f ops/sec\n", phase, phaseOps, phaseThroughput)

		totalOps += phaseOps
	}

	// è®¡ç®—æœ€ç»ˆç»“æœ
	execution.Results = te.calculateTestResults(totalOps, allResponseTimes, allErrors, time.Now().Add(-config.Duration), time.Now())
}

func (te *TestExecutor) runRegressionTest(test *PerformanceTest, execution *TestExecution) {
	fmt.Printf("å›å½’æµ‹è¯•: å¯¹æ¯”å†å²åŸºçº¿æ€§èƒ½\n")

	// æ‰§è¡Œå½“å‰æµ‹è¯•
	te.runBenchmarkTest(test, execution)

	// è·å–å†å²åŸºçº¿æ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰
	baseline := te.getPerformanceBaseline(test.ID)
	if baseline != nil {
		// è¿›è¡Œæ€§èƒ½å¯¹æ¯”åˆ†æ
		currentThroughput := execution.Results.Throughput.OperationsPerSecond
		baselineThroughput := baseline.Throughput.OperationsPerSecond

		regressionThreshold := 0.05 // 5%é˜ˆå€¼
		change := (currentThroughput - baselineThroughput) / baselineThroughput

		if change < -regressionThreshold {
			execution.Errors = append(execution.Errors, ExecutionError{
				Timestamp: time.Now(),
				Type:      "performance_regression",
				Message:   fmt.Sprintf("æ€§èƒ½å›å½’æ£€æµ‹: ååé‡ä¸‹é™ %.2f%%", math.Abs(change)*100),
			})
		}

		fmt.Printf("å›å½’åˆ†æ: å½“å‰ %.2f ops/sec vs åŸºçº¿ %.2f ops/sec (å˜åŒ–: %.2f%%)\n",
			currentThroughput, baselineThroughput, change*100)
	}
}

func (te *TestExecutor) runGenericTest(test *PerformanceTest, execution *TestExecution) {
	// é€šç”¨æµ‹è¯•æ‰§è¡Œé€»è¾‘
	te.runBenchmarkTest(test, execution)
}

func (te *TestExecutor) executeHTTPRequest(target TestTarget) error {
	// HTTPè¯·æ±‚æ‰§è¡Œé€»è¾‘
	client := &http.Client{Timeout: 10 * time.Second}

	var body io.Reader
	if target.Body != nil {
		body = bytes.NewReader(target.Body)
	}

	req, err := http.NewRequest(target.Method, target.Endpoint, body)
	if err != nil {
		return err
	}

	for key, value := range target.Headers {
		req.Header.Set(key, value)
	}

	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	if resp.StatusCode >= 400 {
		return fmt.Errorf("HTTP error: %d", resp.StatusCode)
	}

	return nil
}

func (te *TestExecutor) calculateTestResults(operations int64, responseTimes []time.Duration, errors []ExecutionError, startTime, endTime time.Time) TestResults {
	if len(responseTimes) == 0 {
		return TestResults{
			TotalOperations: operations,
			FailedOps:       int64(len(errors)),
		}
	}

	// æ’åºå“åº”æ—¶é—´
	sort.Slice(responseTimes, func(i, j int) bool {
		return responseTimes[i] < responseTimes[j]
	})

	// è®¡ç®—ç»Ÿè®¡å€¼
	duration := endTime.Sub(startTime)
	count := len(responseTimes)

	results := TestResults{
		TotalOperations: operations,
		SuccessfulOps:   operations - int64(len(errors)),
		FailedOps:       int64(len(errors)),
		ResponseTimes: ResponseTimeStats{
			Min:    responseTimes[0],
			Max:    responseTimes[count-1],
			Median: responseTimes[count/2],
			P90:    responseTimes[int(float64(count)*0.9)],
			P95:    responseTimes[int(float64(count)*0.95)],
			P99:    responseTimes[int(float64(count)*0.99)],
		},
		Throughput: ThroughputStats{
			OperationsPerSecond: float64(operations) / duration.Seconds(),
		},
		ErrorDistribution: make(map[string]int64),
		CustomMetrics:     make(map[string]float64),
	}

	// è®¡ç®—å¹³å‡å“åº”æ—¶é—´
	var total time.Duration
	for _, rt := range responseTimes {
		total += rt
	}
	results.ResponseTimes.Mean = total / time.Duration(count)

	// ç»Ÿè®¡é”™è¯¯åˆ†å¸ƒ
	for _, err := range errors {
		results.ErrorDistribution[err.Type]++
	}

	return results
}

func (te *TestExecutor) getPerformanceBaseline(testID string) *TestResults {
	// æ¨¡æ‹Ÿè·å–å†å²åŸºçº¿æ•°æ®
	return &TestResults{
		Throughput: ThroughputStats{
			OperationsPerSecond: 1000.0, // æ¨¡æ‹ŸåŸºçº¿å€¼
		},
	}
}

// ==================
// 3. æ€§èƒ½æŠ¥å‘Šç”Ÿæˆå™¨
// ==================

// PerformanceReporter æ€§èƒ½æŠ¥å‘Šç”Ÿæˆå™¨
type PerformanceReporter struct {
	reports       map[string]*PerformanceReport
	templates     map[string]*ReportTemplate
	exporters     map[string]ReportExporter
	dashboards    map[string]*Dashboard
	notifications []NotificationConfig
	mutex         sync.RWMutex
}

// PerformanceReport æ€§èƒ½æŠ¥å‘Š
type PerformanceReport struct {
	ID              string
	Title           string
	GeneratedAt     time.Time
	Period          ReportPeriod
	TestSummary     TestSummary
	TrendAnalysis   TrendAnalysis
	Comparisons     []PerformanceComparison
	Recommendations []PerformanceRecommendation
	Attachments     []ReportAttachment
	Metadata        map[string]interface{}
}

// ReportPeriod æŠ¥å‘Šå‘¨æœŸ
type ReportPeriod struct {
	StartTime time.Time
	EndTime   time.Time
	Duration  time.Duration
	Type      PeriodType
}

// PeriodType å‘¨æœŸç±»å‹
type PeriodType int

const (
	Hourly PeriodType = iota
	Daily
	Weekly
	Monthly
	Custom
)

// TestSummary æµ‹è¯•æ‘˜è¦
type TestSummary struct {
	TotalTests       int
	PassedTests      int
	FailedTests      int
	SkippedTests     int
	AvgDuration      time.Duration
	TotalDuration    time.Duration
	SuccessRate      float64
	RegressionCount  int
	ImprovementCount int
}

// TrendAnalysis è¶‹åŠ¿åˆ†æ
type TrendAnalysis struct {
	PerformanceTrend   TrendDirection
	ThroughputTrend    TrendDirection
	ErrorRateTrend     TrendDirection
	LatencyTrend       TrendDirection
	TrendConfidence    float64
	SignificantChanges []SignificantChange
}

// TrendDirection è¶‹åŠ¿æ–¹å‘
type TrendDirection int

const (
	TrendImproving TrendDirection = iota
	TrendStable
	TrendDegrading
	TrendUnknown
)

// SignificantChange æ˜¾è‘—å˜åŒ–
type SignificantChange struct {
	Metric      string
	Change      float64
	Confidence  float64
	Impact      ImpactLevel
	Description string
}

// ImpactLevel å½±å“çº§åˆ«
type ImpactLevel int

const (
	LowImpact ImpactLevel = iota
	MediumImpact
	HighImpact
	CriticalImpact
)

// PerformanceComparison æ€§èƒ½å¯¹æ¯”
type PerformanceComparison struct {
	Name       string
	Baseline   string
	Current    string
	Metrics    map[string]ComparisonMetric
	Conclusion string
}

// ComparisonMetric å¯¹æ¯”æŒ‡æ ‡
type ComparisonMetric struct {
	BaselineValue float64
	CurrentValue  float64
	Change        float64
	ChangePercent float64
	Significance  float64
}

// PerformanceRecommendation æ€§èƒ½å»ºè®®
type PerformanceRecommendation struct {
	Type        RecommendationType
	Priority    Priority
	Title       string
	Description string
	Impact      string
	Effort      string
	Actions     []string
	Evidence    []string
}

// RecommendationType å»ºè®®ç±»å‹
type RecommendationType int

const (
	OptimizationRecommendation RecommendationType = iota
	ScalingRecommendation
	ConfigurationRecommendation
	ArchitectureRecommendation
	TestingRecommendation
)

// Priority ä¼˜å…ˆçº§
type Priority int

const (
	LowPriority Priority = iota
	MediumPriority
	HighPriority
	CriticalPriority
)

// ReportAttachment æŠ¥å‘Šé™„ä»¶
type ReportAttachment struct {
	Name     string
	Type     AttachmentType
	Content  []byte
	FilePath string
	URL      string
}

// AttachmentType é™„ä»¶ç±»å‹
type AttachmentType int

const (
	Chart AttachmentType = iota
	Graph
	TableAttachment
	Raw
	Image
)

// ReportTemplate æŠ¥å‘Šæ¨¡æ¿
type ReportTemplate struct {
	Name     string
	Format   ReportFormat
	Sections []TemplateSection
	Styles   map[string]interface{}
}

// ReportFormat æŠ¥å‘Šæ ¼å¼
type ReportFormat int

const (
	HTMLFormat ReportFormat = iota
	PDFFormat
	JSONFormat
	CSVFormat
	ExcelFormat
)

// TemplateSection æ¨¡æ¿éƒ¨åˆ†
type TemplateSection struct {
	Name     string
	Template string
	Data     interface{}
	Order    int
}

// ReportExporter æŠ¥å‘Šå¯¼å‡ºå™¨
type ReportExporter interface {
	Export(report *PerformanceReport) ([]byte, error)
	Format() ReportFormat
}

// Dashboard ä»ªè¡¨æ¿
type Dashboard struct {
	Name    string
	Widgets []DashboardWidget
	Layout  DashboardLayout
	Refresh time.Duration
}

// DashboardWidget ä»ªè¡¨æ¿ç»„ä»¶
type DashboardWidget struct {
	Type   WidgetType
	Title  string
	Query  string
	Config map[string]interface{}
}

// WidgetType ç»„ä»¶ç±»å‹
type WidgetType int

const (
	LineChart WidgetType = iota
	BarChart
	PieChart
	Gauge
	Table
	Text
)

// DashboardLayout ä»ªè¡¨æ¿å¸ƒå±€
type DashboardLayout struct {
	Rows    int
	Columns int
	Widgets map[string]WidgetPosition
}

// WidgetPosition ç»„ä»¶ä½ç½®
type WidgetPosition struct {
	Row    int
	Column int
	Width  int
	Height int
}

// NotificationConfig é€šçŸ¥é…ç½®
type NotificationConfig struct {
	Type     NotificationType
	Target   string
	Triggers []NotificationTrigger
	Template string
	Enabled  bool
}

// NotificationType é€šçŸ¥ç±»å‹
type NotificationType int

const (
	EmailNotification NotificationType = iota
	SlackNotification
	WebhookNotification
	SMSNotification
)

// NotificationTrigger é€šçŸ¥è§¦å‘å™¨
type NotificationTrigger struct {
	Condition string
	Threshold float64
	Operator  ComparisonOperator
}

func NewPerformanceReporter() *PerformanceReporter {
	reporter := &PerformanceReporter{
		reports:    make(map[string]*PerformanceReport),
		templates:  make(map[string]*ReportTemplate),
		exporters:  make(map[string]ReportExporter),
		dashboards: make(map[string]*Dashboard),
	}

	// æ³¨å†Œé»˜è®¤å¯¼å‡ºå™¨
	reporter.exporters["html"] = &HTMLExporter{}
	reporter.exporters["json"] = &JSONExporter{}

	// åˆ›å»ºé»˜è®¤æ¨¡æ¿
	reporter.createDefaultTemplates()

	return reporter
}

func (pr *PerformanceReporter) GenerateReport(executions []*TestExecution, period ReportPeriod) *PerformanceReport {
	report := &PerformanceReport{
		ID:          generateReportID(),
		Title:       fmt.Sprintf("æ€§èƒ½æµ‹è¯•æŠ¥å‘Š - %s", period.StartTime.Format("2006-01-02")),
		GeneratedAt: time.Now(),
		Period:      period,
		Metadata:    make(map[string]interface{}),
	}

	// ç”Ÿæˆæµ‹è¯•æ‘˜è¦
	report.TestSummary = pr.generateTestSummary(executions)

	// ç”Ÿæˆè¶‹åŠ¿åˆ†æ
	report.TrendAnalysis = pr.generateTrendAnalysis(executions)

	// ç”Ÿæˆæ€§èƒ½å¯¹æ¯”
	report.Comparisons = pr.generateComparisons(executions)

	// ç”Ÿæˆä¼˜åŒ–å»ºè®®
	report.Recommendations = pr.generateRecommendations(executions)

	pr.mutex.Lock()
	pr.reports[report.ID] = report
	pr.mutex.Unlock()

	fmt.Printf("ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š: %s\n", report.ID)
	return report
}

func (pr *PerformanceReporter) generateTestSummary(executions []*TestExecution) TestSummary {
	summary := TestSummary{}

	var totalDuration time.Duration
	for _, exec := range executions {
		summary.TotalTests++
		totalDuration += exec.Duration

		switch exec.Status {
		case StatusCompleted:
			summary.PassedTests++
		case StatusFailed:
			summary.FailedTests++
		default:
			summary.SkippedTests++
		}
	}

	if summary.TotalTests > 0 {
		summary.AvgDuration = totalDuration / time.Duration(summary.TotalTests)
		summary.SuccessRate = float64(summary.PassedTests) / float64(summary.TotalTests) * 100
	}

	summary.TotalDuration = totalDuration

	return summary
}

func (pr *PerformanceReporter) generateTrendAnalysis(executions []*TestExecution) TrendAnalysis {
	analysis := TrendAnalysis{
		SignificantChanges: make([]SignificantChange, 0),
	}

	if len(executions) < 2 {
		analysis.PerformanceTrend = TrendUnknown
		return analysis
	}

	// ç®€åŒ–çš„è¶‹åŠ¿åˆ†æ
	var throughputValues []float64
	var latencyValues []float64

	for _, exec := range executions {
		throughputValues = append(throughputValues, exec.Results.Throughput.OperationsPerSecond)
		latencyValues = append(latencyValues, float64(exec.Results.ResponseTimes.Mean.Milliseconds()))
	}

	// åˆ†æååé‡è¶‹åŠ¿
	if pr.calculateTrend(throughputValues) > 0.05 {
		analysis.ThroughputTrend = TrendImproving
		analysis.SignificantChanges = append(analysis.SignificantChanges, SignificantChange{
			Metric:      "throughput",
			Change:      pr.calculateTrend(throughputValues),
			Confidence:  0.85,
			Impact:      MediumImpact,
			Description: "ååé‡æ˜¾è‘—æå‡",
		})
	} else if pr.calculateTrend(throughputValues) < -0.05 {
		analysis.ThroughputTrend = TrendDegrading
	} else {
		analysis.ThroughputTrend = TrendStable
	}

	// åˆ†æå»¶è¿Ÿè¶‹åŠ¿
	if pr.calculateTrend(latencyValues) < -0.05 {
		analysis.LatencyTrend = TrendImproving
	} else if pr.calculateTrend(latencyValues) > 0.05 {
		analysis.LatencyTrend = TrendDegrading
	} else {
		analysis.LatencyTrend = TrendStable
	}

	// ç»¼åˆè¯„ä¼°
	if analysis.ThroughputTrend == TrendImproving && analysis.LatencyTrend == TrendImproving {
		analysis.PerformanceTrend = TrendImproving
	} else if analysis.ThroughputTrend == TrendDegrading || analysis.LatencyTrend == TrendDegrading {
		analysis.PerformanceTrend = TrendDegrading
	} else {
		analysis.PerformanceTrend = TrendStable
	}

	analysis.TrendConfidence = 0.8

	return analysis
}

func (pr *PerformanceReporter) calculateTrend(values []float64) float64 {
	if len(values) < 2 {
		return 0
	}

	// ç®€å•çš„çº¿æ€§è¶‹åŠ¿è®¡ç®—
	first := values[0]
	last := values[len(values)-1]

	if first == 0 {
		return 0
	}

	return (last - first) / first
}

func (pr *PerformanceReporter) generateComparisons(executions []*TestExecution) []PerformanceComparison {
	comparisons := make([]PerformanceComparison, 0)

	if len(executions) >= 2 {
		// å¯¹æ¯”æœ€æ–°å’Œå‰ä¸€æ¬¡æ‰§è¡Œ
		current := executions[len(executions)-1]
		previous := executions[len(executions)-2]

		comparison := PerformanceComparison{
			Name:     "æœ€æ–° vs å‰æ¬¡",
			Baseline: previous.ID,
			Current:  current.ID,
			Metrics:  make(map[string]ComparisonMetric),
		}

		// å¯¹æ¯”ååé‡
		if previous.Results.Throughput.OperationsPerSecond > 0 {
			throughputChange := (current.Results.Throughput.OperationsPerSecond - previous.Results.Throughput.OperationsPerSecond) / previous.Results.Throughput.OperationsPerSecond * 100

			comparison.Metrics["throughput"] = ComparisonMetric{
				BaselineValue: previous.Results.Throughput.OperationsPerSecond,
				CurrentValue:  current.Results.Throughput.OperationsPerSecond,
				ChangePercent: throughputChange,
			}
		}

		// å¯¹æ¯”å»¶è¿Ÿ
		prevLatency := float64(previous.Results.ResponseTimes.Mean.Milliseconds())
		currLatency := float64(current.Results.ResponseTimes.Mean.Milliseconds())

		if prevLatency > 0 {
			latencyChange := (currLatency - prevLatency) / prevLatency * 100

			comparison.Metrics["latency"] = ComparisonMetric{
				BaselineValue: prevLatency,
				CurrentValue:  currLatency,
				ChangePercent: latencyChange,
			}
		}

		comparisons = append(comparisons, comparison)
	}

	return comparisons
}

func (pr *PerformanceReporter) generateRecommendations(executions []*TestExecution) []PerformanceRecommendation {
	recommendations := make([]PerformanceRecommendation, 0)

	if len(executions) == 0 {
		return recommendations
	}

	latest := executions[len(executions)-1]

	// åŸºäºé”™è¯¯ç‡çš„å»ºè®®
	if latest.Results.FailedOps > 0 {
		errorRate := float64(latest.Results.FailedOps) / float64(latest.Results.TotalOperations) * 100
		if errorRate > 5.0 {
			recommendations = append(recommendations, PerformanceRecommendation{
				Type:        OptimizationRecommendation,
				Priority:    HighPriority,
				Title:       "é™ä½é”™è¯¯ç‡",
				Description: fmt.Sprintf("å½“å‰é”™è¯¯ç‡ä¸º %.2f%%ï¼Œè¶…è¿‡äº†5%%çš„é˜ˆå€¼", errorRate),
				Impact:      "æé«˜ç³»ç»Ÿç¨³å®šæ€§å’Œç”¨æˆ·ä½“éªŒ",
				Effort:      "ä¸­ç­‰",
				Actions: []string{
					"æ£€æŸ¥é”™è¯¯æ—¥å¿—æ‰¾å‡ºæ ¹æœ¬åŸå› ",
					"æ·»åŠ é‡è¯•æœºåˆ¶",
					"ä¼˜åŒ–é”™è¯¯å¤„ç†é€»è¾‘",
				},
			})
		}
	}

	// åŸºäºå“åº”æ—¶é—´çš„å»ºè®®
	if latest.Results.ResponseTimes.P95 > 500*time.Millisecond {
		recommendations = append(recommendations, PerformanceRecommendation{
			Type:        OptimizationRecommendation,
			Priority:    MediumPriority,
			Title:       "ä¼˜åŒ–å“åº”æ—¶é—´",
			Description: fmt.Sprintf("P95å“åº”æ—¶é—´ä¸º %vï¼Œå»ºè®®ä¼˜åŒ–", latest.Results.ResponseTimes.P95),
			Impact:      "æ”¹å–„ç”¨æˆ·ä½“éªŒ",
			Effort:      "ä¸­ç­‰åˆ°é«˜",
			Actions: []string{
				"åˆ†ææ…¢æŸ¥è¯¢å’Œç“¶é¢ˆ",
				"æ·»åŠ ç¼“å­˜å±‚",
				"ä¼˜åŒ–æ•°æ®åº“ç´¢å¼•",
				"è€ƒè™‘å¼‚æ­¥å¤„ç†",
			},
		})
	}

	// åŸºäºååé‡çš„å»ºè®®
	if latest.Results.Throughput.OperationsPerSecond < 100 {
		recommendations = append(recommendations, PerformanceRecommendation{
			Type:        ScalingRecommendation,
			Priority:    MediumPriority,
			Title:       "æå‡ç³»ç»Ÿååé‡",
			Description: "å½“å‰ååé‡è¾ƒä½ï¼Œå»ºè®®è¿›è¡Œæ‰©å®¹æˆ–ä¼˜åŒ–",
			Impact:      "æ”¯æŒæ›´é«˜çš„å¹¶å‘è´Ÿè½½",
			Effort:      "ä¸­ç­‰",
			Actions: []string{
				"å¢åŠ æœåŠ¡å™¨å®ä¾‹",
				"ä¼˜åŒ–å¹¶å‘å¤„ç†",
				"ä½¿ç”¨è¿æ¥æ± ",
				"å®æ–½è´Ÿè½½å‡è¡¡",
			},
		})
	}

	return recommendations
}

func (pr *PerformanceReporter) createDefaultTemplates() {
	// åˆ›å»ºHTMLæ¨¡æ¿
	htmlTemplate := &ReportTemplate{
		Name:   "default_html",
		Format: HTMLFormat,
		Sections: []TemplateSection{
			{Name: "summary", Template: "summary.html", Order: 1},
			{Name: "trends", Template: "trends.html", Order: 2},
			{Name: "comparisons", Template: "comparisons.html", Order: 3},
			{Name: "recommendations", Template: "recommendations.html", Order: 4},
		},
	}

	pr.templates["html"] = htmlTemplate
}

func (pr *PerformanceReporter) ExportReport(reportID string, format ReportFormat) ([]byte, error) {
	pr.mutex.RLock()
	report, exists := pr.reports[reportID]
	pr.mutex.RUnlock()

	if !exists {
		return nil, fmt.Errorf("report not found: %s", reportID)
	}

	var formatName string
	switch format {
	case HTMLFormat:
		formatName = "html"
	case JSONFormat:
		formatName = "json"
	default:
		return nil, fmt.Errorf("unsupported format")
	}

	exporter, exists := pr.exporters[formatName]
	if !exists {
		return nil, fmt.Errorf("exporter not found for format: %s", formatName)
	}

	return exporter.Export(report)
}

// ==================
// 4. å¯¼å‡ºå™¨å®ç°
// ==================

// HTMLExporter HTMLå¯¼å‡ºå™¨
type HTMLExporter struct{}

func (he *HTMLExporter) Export(report *PerformanceReport) ([]byte, error) {
	html := fmt.Sprintf(`
<!DOCTYPE html>
<html>
<head>
    <title>%s</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .summary { background: #f5f5f5; padding: 20px; border-radius: 5px; }
        .metric { margin: 10px 0; }
        .recommendations { margin-top: 30px; }
        .recommendation { background: #e8f4fd; padding: 15px; margin: 10px 0; border-radius: 5px; }
    </style>
</head>
<body>
    <h1>%s</h1>
    <p>ç”Ÿæˆæ—¶é—´: %s</p>

    <div class="summary">
        <h2>æµ‹è¯•æ‘˜è¦</h2>
        <div class="metric">æ€»æµ‹è¯•æ•°: %d</div>
        <div class="metric">é€šè¿‡ç‡: %.2f%%</div>
        <div class="metric">å¹³å‡æ‰§è¡Œæ—¶é—´: %v</div>
    </div>

    <div class="recommendations">
        <h2>ä¼˜åŒ–å»ºè®® (%dæ¡)</h2>
        %s
    </div>
</body>
</html>
	`, report.Title, report.Title, report.GeneratedAt.Format("2006-01-02 15:04:05"),
		report.TestSummary.TotalTests, report.TestSummary.SuccessRate, report.TestSummary.AvgDuration,
		len(report.Recommendations), he.renderRecommendations(report.Recommendations))

	return []byte(html), nil
}

func (he *HTMLExporter) Format() ReportFormat {
	return HTMLFormat
}

func (he *HTMLExporter) renderRecommendations(recommendations []PerformanceRecommendation) string {
	var html strings.Builder
	for _, rec := range recommendations {
		html.WriteString(fmt.Sprintf(`
        <div class="recommendation">
            <h3>%s (ä¼˜å…ˆçº§: %d)</h3>
            <p>%s</p>
            <p><strong>å½±å“:</strong> %s</p>
            <p><strong>å·¥ä½œé‡:</strong> %s</p>
        </div>
		`, rec.Title, int(rec.Priority), rec.Description, rec.Impact, rec.Effort))
	}
	return html.String()
}

// JSONExporter JSONå¯¼å‡ºå™¨
type JSONExporter struct{}

func (je *JSONExporter) Export(report *PerformanceReport) ([]byte, error) {
	return json.MarshalIndent(report, "", "  ")
}

func (je *JSONExporter) Format() ReportFormat {
	return JSONFormat
}

// ==================
// 5. æŒ‡æ ‡æ”¶é›†å™¨
// ==================

// MetricsCollector æŒ‡æ ‡æ”¶é›†å™¨
type MetricsCollector struct {
	metrics    map[string]*MetricSeries
	aggregates map[string]*AggregatedMetric
	config     CollectorConfig
	running    bool
	stopCh     chan struct{}
	mutex      sync.RWMutex
}

// CollectorConfig æ”¶é›†å™¨é…ç½®
type CollectorConfig struct {
	CollectionInterval time.Duration
	RetentionPeriod    time.Duration
	AggregationWindow  time.Duration
	MaxMetrics         int
}

// MetricSeries æŒ‡æ ‡åºåˆ—
type MetricSeries struct {
	Name       string
	Points     []MetricPoint
	Labels     map[string]string
	LastUpdate time.Time
}

// MetricPoint æŒ‡æ ‡ç‚¹
type MetricPoint struct {
	Timestamp time.Time
	Value     float64
	Tags      map[string]string
}

// AggregatedMetric èšåˆæŒ‡æ ‡
type AggregatedMetric struct {
	Name   string
	Count  int64
	Sum    float64
	Min    float64
	Max    float64
	Mean   float64
	StdDev float64
	P50    float64
	P90    float64
	P95    float64
	P99    float64
}

func NewMetricsCollector() *MetricsCollector {
	return &MetricsCollector{
		metrics:    make(map[string]*MetricSeries),
		aggregates: make(map[string]*AggregatedMetric),
		config: CollectorConfig{
			CollectionInterval: time.Second,
			RetentionPeriod:    24 * time.Hour,
			AggregationWindow:  time.Minute,
			MaxMetrics:         10000,
		},
		stopCh: make(chan struct{}),
	}
}

func (mc *MetricsCollector) Run() {
	mc.running = true
	ticker := time.NewTicker(mc.config.CollectionInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			mc.collectSystemMetrics()
			mc.aggregateMetrics()
			mc.cleanupOldMetrics()

		case <-mc.stopCh:
			mc.running = false
			return
		}
	}
}

func (mc *MetricsCollector) collectSystemMetrics() {
	// æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
	var m runtime.MemStats
	runtime.ReadMemStats(&m)

	now := time.Now()

	// å†…å­˜æŒ‡æ ‡
	mc.RecordMetric("heap_inuse", float64(m.HeapInuse), nil, now)
	mc.RecordMetric("heap_sys", float64(m.HeapSys), nil, now)
	mc.RecordMetric("gc_runs", float64(m.NumGC), nil, now)

	// GoroutineæŒ‡æ ‡
	mc.RecordMetric("goroutines", float64(runtime.NumGoroutine()), nil, now)

	// CPUæŒ‡æ ‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
	mc.RecordMetric("cpu_cores", float64(runtime.NumCPU()), nil, now)
}

func (mc *MetricsCollector) RecordMetric(name string, value float64, labels map[string]string, timestamp time.Time) {
	mc.mutex.Lock()
	defer mc.mutex.Unlock()

	key := mc.getMetricKey(name, labels)
	series, exists := mc.metrics[key]
	if !exists {
		series = &MetricSeries{
			Name:   name,
			Points: make([]MetricPoint, 0),
			Labels: labels,
		}
		mc.metrics[key] = series
	}

	point := MetricPoint{
		Timestamp: timestamp,
		Value:     value,
		Tags:      labels,
	}

	series.Points = append(series.Points, point)
	series.LastUpdate = timestamp

	// é™åˆ¶ç‚¹æ•°
	if len(series.Points) > 1000 {
		series.Points = series.Points[100:]
	}
}

func (mc *MetricsCollector) getMetricKey(name string, labels map[string]string) string {
	var parts []string
	parts = append(parts, name)

	if labels != nil {
		var keys []string
		for k := range labels {
			keys = append(keys, k)
		}
		sort.Strings(keys)

		for _, k := range keys {
			parts = append(parts, fmt.Sprintf("%s=%s", k, labels[k]))
		}
	}

	return strings.Join(parts, "|")
}

func (mc *MetricsCollector) aggregateMetrics() {
	mc.mutex.Lock()
	defer mc.mutex.Unlock()

	cutoff := time.Now().Add(-mc.config.AggregationWindow)

	for key, series := range mc.metrics {
		// è·å–æ—¶é—´çª—å£å†…çš„ç‚¹
		var values []float64
		for _, point := range series.Points {
			if point.Timestamp.After(cutoff) {
				values = append(values, point.Value)
			}
		}

		if len(values) == 0 {
			continue
		}

		// è®¡ç®—èšåˆæŒ‡æ ‡
		aggregate := mc.calculateAggregation(values)
		aggregate.Name = series.Name
		mc.aggregates[key] = aggregate
	}
}

func (mc *MetricsCollector) calculateAggregation(values []float64) *AggregatedMetric {
	if len(values) == 0 {
		return &AggregatedMetric{}
	}

	sort.Float64s(values)
	count := len(values)

	// åŸºæœ¬ç»Ÿè®¡
	sum := 0.0
	min := values[0]
	max := values[count-1]

	for _, v := range values {
		sum += v
	}

	mean := sum / float64(count)

	// æ ‡å‡†å·®
	variance := 0.0
	for _, v := range values {
		variance += math.Pow(v-mean, 2)
	}
	stdDev := math.Sqrt(variance / float64(count))

	// ç™¾åˆ†ä½æ•°
	p50 := values[count/2]
	p90 := values[int(float64(count)*0.9)]
	p95 := values[int(float64(count)*0.95)]
	p99 := values[int(float64(count)*0.99)]

	return &AggregatedMetric{
		Count:  int64(count),
		Sum:    sum,
		Min:    min,
		Max:    max,
		Mean:   mean,
		StdDev: stdDev,
		P50:    p50,
		P90:    p90,
		P95:    p95,
		P99:    p99,
	}
}

func (mc *MetricsCollector) cleanupOldMetrics() {
	mc.mutex.Lock()
	defer mc.mutex.Unlock()

	cutoff := time.Now().Add(-mc.config.RetentionPeriod)

	for key, series := range mc.metrics {
		if series.LastUpdate.Before(cutoff) {
			delete(mc.metrics, key)
			delete(mc.aggregates, key)
		}
	}
}

func (mc *MetricsCollector) GetMetrics(name string, labels map[string]string) *MetricSeries {
	mc.mutex.RLock()
	defer mc.mutex.RUnlock()

	key := mc.getMetricKey(name, labels)
	return mc.metrics[key]
}

func (mc *MetricsCollector) GetAggregatedMetric(name string, labels map[string]string) *AggregatedMetric {
	mc.mutex.RLock()
	defer mc.mutex.RUnlock()

	key := mc.getMetricKey(name, labels)
	return mc.aggregates[key]
}

// ==================
// 6. å‘Šè­¦ç®¡ç†å™¨
// ==================

// AlertManager å‘Šè­¦ç®¡ç†å™¨
type AlertManager struct {
	rules      []AlertRule
	alerts     map[string]*Alert
	channels   []AlertChannel
	silences   []AlertSilence
	escalation AlertEscalation
	mutex      sync.RWMutex
	running    bool
	stopCh     chan struct{}
}

// AlertRule å‘Šè­¦è§„åˆ™
type AlertRule struct {
	ID          string
	Name        string
	Query       string
	Condition   AlertCondition
	Threshold   float64
	Duration    time.Duration
	Severity    AlertSeverity
	Labels      map[string]string
	Annotations map[string]string
	Enabled     bool
}

// Alert å‘Šè­¦
type Alert struct {
	ID          string
	RuleID      string
	Name        string
	Status      AlertStatus
	Value       float64
	Threshold   float64
	StartsAt    time.Time
	EndsAt      *time.Time
	UpdatedAt   time.Time
	Severity    AlertSeverity
	Labels      map[string]string
	Annotations map[string]string
}

// AlertCondition å‘Šè­¦æ¡ä»¶
type AlertCondition int

const (
	AlertGreaterThan AlertCondition = iota
	AlertLessThan
	AlertEqual
	AlertNotEqual
	Above
	Below
)

// AlertStatus å‘Šè­¦çŠ¶æ€
type AlertStatus int

const (
	AlertPending AlertStatus = iota
	AlertFiring
	AlertResolved
	AlertSilenced
)

// AlertSeverity å‘Šè­¦ä¸¥é‡ç¨‹åº¦
type AlertSeverity int

const (
	SeverityInfo AlertSeverity = iota
	SeverityWarning
	SeverityCritical
	SeverityEmergency
)

// AlertChannel å‘Šè­¦é€šé“
type AlertChannel interface {
	SendAlert(alert *Alert) error
	Name() string
}

// AlertSilence å‘Šè­¦é™é»˜
type AlertSilence struct {
	ID       string
	Matchers []SilenceMatcher
	StartsAt time.Time
	EndsAt   time.Time
	Creator  string
	Comment  string
}

// SilenceMatcher é™é»˜åŒ¹é…å™¨
type SilenceMatcher struct {
	Name  string
	Value string
	Regex bool
}

// AlertEscalation å‘Šè­¦å‡çº§
type AlertEscalation struct {
	Rules []EscalationRule
}

// EscalationRule å‡çº§è§„åˆ™
type EscalationRule struct {
	Duration time.Duration
	Severity AlertSeverity
	Channels []string
	OnlyOnce bool
}

func NewAlertManager() *AlertManager {
	return &AlertManager{
		rules:    make([]AlertRule, 0),
		alerts:   make(map[string]*Alert),
		channels: make([]AlertChannel, 0),
		silences: make([]AlertSilence, 0),
		stopCh:   make(chan struct{}),
	}
}

func (am *AlertManager) Run() {
	am.running = true
	ticker := time.NewTicker(10 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			am.evaluateRules()
			am.processAlerts()

		case <-am.stopCh:
			am.running = false
			return
		}
	}
}

func (am *AlertManager) AddRule(rule AlertRule) {
	am.mutex.Lock()
	defer am.mutex.Unlock()

	am.rules = append(am.rules, rule)
	fmt.Printf("æ·»åŠ å‘Šè­¦è§„åˆ™: %s\n", rule.Name)
}

func (am *AlertManager) AddChannel(channel AlertChannel) {
	am.mutex.Lock()
	defer am.mutex.Unlock()

	am.channels = append(am.channels, channel)
	fmt.Printf("æ·»åŠ å‘Šè­¦é€šé“: %s\n", channel.Name())
}

func (am *AlertManager) evaluateRules() {
	am.mutex.RLock()
	rules := make([]AlertRule, len(am.rules))
	copy(rules, am.rules)
	am.mutex.RUnlock()

	for _, rule := range rules {
		if !rule.Enabled {
			continue
		}

		value := am.evaluateQuery(rule.Query)
		shouldAlert := am.checkCondition(rule.Condition, value, rule.Threshold)

		am.mutex.Lock()
		existingAlert, exists := am.alerts[rule.ID]

		if shouldAlert && !exists {
			// åˆ›å»ºæ–°å‘Šè­¦
			alert := &Alert{
				ID:          generateAlertID(),
				RuleID:      rule.ID,
				Name:        rule.Name,
				Status:      AlertFiring,
				Value:       value,
				Threshold:   rule.Threshold,
				StartsAt:    time.Now(),
				UpdatedAt:   time.Now(),
				Severity:    rule.Severity,
				Labels:      rule.Labels,
				Annotations: rule.Annotations,
			}
			am.alerts[rule.ID] = alert
			fmt.Printf("ğŸš¨ æ–°å‘Šè­¦: %s (å€¼: %.2f, é˜ˆå€¼: %.2f)\n", rule.Name, value, rule.Threshold)

		} else if !shouldAlert && exists && existingAlert.Status == AlertFiring {
			// è§£å†³å‘Šè­¦
			now := time.Now()
			existingAlert.Status = AlertResolved
			existingAlert.EndsAt = &now
			existingAlert.UpdatedAt = now
			fmt.Printf("âœ… å‘Šè­¦å·²è§£å†³: %s\n", rule.Name)

		} else if exists {
			// æ›´æ–°ç°æœ‰å‘Šè­¦
			existingAlert.Value = value
			existingAlert.UpdatedAt = time.Now()
		}

		am.mutex.Unlock()
	}
}

func (am *AlertManager) evaluateQuery(query string) float64 {
	// ç®€åŒ–çš„æŸ¥è¯¢è¯„ä¼°é€»è¾‘
	// å®é™…å®ç°ä¼šè¿æ¥åˆ°æŒ‡æ ‡æ”¶é›†å™¨æˆ–æ—¶åºæ•°æ®åº“
	switch query {
	case "response_time_p95":
		return float64(200 + secureRandomInt(300)) // æ¨¡æ‹Ÿå“åº”æ—¶é—´
	case "error_rate":
		return secureRandomFloat64() * 10 // æ¨¡æ‹Ÿé”™è¯¯ç‡
	case "throughput":
		return float64(800 + secureRandomInt(400)) // æ¨¡æ‹Ÿååé‡
	default:
		return secureRandomFloat64() * 100
	}
}

func (am *AlertManager) checkCondition(condition AlertCondition, value, threshold float64) bool {
	switch condition {
	case AlertGreaterThan:
		return value > threshold
	case AlertLessThan:
		return value < threshold
	case AlertEqual:
		return math.Abs(value-threshold) < 0.001
	case AlertNotEqual:
		return math.Abs(value-threshold) >= 0.001
	default:
		return false
	}
}

func (am *AlertManager) processAlerts() {
	am.mutex.RLock()
	alerts := make([]*Alert, 0, len(am.alerts))
	for _, alert := range am.alerts {
		alerts = append(alerts, alert)
	}
	am.mutex.RUnlock()

	for _, alert := range alerts {
		if alert.Status == AlertFiring {
			am.sendAlert(alert)
		}
	}
}

func (am *AlertManager) sendAlert(alert *Alert) {
	if am.isSilenced(alert) {
		return
	}

	for _, channel := range am.channels {
		go func(ch AlertChannel) {
			if err := ch.SendAlert(alert); err != nil {
				fmt.Printf("å‘é€å‘Šè­¦å¤±è´¥: %v\n", err)
			}
		}(channel)
	}
}

func (am *AlertManager) isSilenced(alert *Alert) bool {
	now := time.Now()
	for _, silence := range am.silences {
		if silence.StartsAt.Before(now) && silence.EndsAt.After(now) {
			// æ£€æŸ¥åŒ¹é…æ¡ä»¶
			if am.matchesSilence(alert, silence.Matchers) {
				return true
			}
		}
	}
	return false
}

func (am *AlertManager) matchesSilence(alert *Alert, matchers []SilenceMatcher) bool {
	for _, matcher := range matchers {
		if value, exists := alert.Labels[matcher.Name]; exists {
			if value != matcher.Value {
				return false
			}
		}
	}
	return true
}

// ==================
// 7. CI/CDé›†æˆå™¨
// ==================

// CICDIntegrator CI/CDé›†æˆå™¨
type CICDIntegrator struct {
	pipelines map[string]*Pipeline
	webhooks  []WebhookConfig
	artifacts []ArtifactConfig
	gates     []QualityGate
	reports   []ReportConfig
	mutex     sync.RWMutex
}

// Pipeline æµæ°´çº¿
type Pipeline struct {
	ID       string
	Name     string
	Stages   []PipelineStage
	Triggers []PipelineTrigger
	Status   PipelineStatus
}

// PipelineStage æµæ°´çº¿é˜¶æ®µ
type PipelineStage struct {
	Name     string
	Type     StageType
	Config   map[string]interface{}
	Tests    []string
	Timeout  time.Duration
	Parallel bool
}

// StageType é˜¶æ®µç±»å‹
type StageType int

const (
	BuildStage StageType = iota
	TestStage
	PerformanceStage
	DeployStage
	VerifyStage
)

// PipelineTrigger æµæ°´çº¿è§¦å‘å™¨
type PipelineTrigger struct {
	Type       TriggerType
	Source     string
	Conditions []string
}

// PipelineStatus æµæ°´çº¿çŠ¶æ€
type PipelineStatus int

const (
	PipelinePending PipelineStatus = iota
	PipelineRunning
	PipelineSuccess
	PipelineFailed
	PipelineCancelled
)

// WebhookConfig Webhooké…ç½®
type WebhookConfig struct {
	URL     string
	Events  []WebhookEvent
	Headers map[string]string
	Secret  string
}

// WebhookEvent Webhookäº‹ä»¶
type WebhookEvent int

const (
	TestStarted WebhookEvent = iota
	TestCompleted
	TestFailed
	ReportGenerated
)

// ArtifactConfig äº§ç‰©é…ç½®
type ArtifactConfig struct {
	Name        string
	Path        string
	Type        ArtifactType
	Retention   time.Duration
	Compression bool
}

// ArtifactType äº§ç‰©ç±»å‹
type ArtifactType int

const (
	ReportArtifact ArtifactType = iota
	LogArtifact
	ProfileArtifact
	DataArtifact
)

// QualityGate è´¨é‡é—¨ç¦
type QualityGate struct {
	Name       string
	Conditions []GateCondition
	Action     GateAction
}

// GateCondition é—¨ç¦æ¡ä»¶
type GateCondition struct {
	Metric    string
	Operator  ComparisonOperator
	Threshold float64
	Required  bool
}

// GateAction é—¨ç¦åŠ¨ä½œ
type GateAction int

const (
	ContinuePipeline GateAction = iota
	FailPipeline
	WarnAndContinue
)

// ReportConfig æŠ¥å‘Šé…ç½®
type ReportConfig struct {
	Format     ReportFormat
	Recipients []string
	Template   string
	Frequency  time.Duration
}

func NewCICDIntegrator() *CICDIntegrator {
	return &CICDIntegrator{
		pipelines: make(map[string]*Pipeline),
		webhooks:  make([]WebhookConfig, 0),
		artifacts: make([]ArtifactConfig, 0),
		gates:     make([]QualityGate, 0),
		reports:   make([]ReportConfig, 0),
	}
}

func (ci *CICDIntegrator) RegisterPipeline(pipeline *Pipeline) {
	ci.mutex.Lock()
	defer ci.mutex.Unlock()

	ci.pipelines[pipeline.ID] = pipeline
	fmt.Printf("æ³¨å†ŒCI/CDæµæ°´çº¿: %s\n", pipeline.Name)
}

func (ci *CICDIntegrator) TriggerPipeline(pipelineID string, context map[string]interface{}) error {
	ci.mutex.RLock()
	pipeline, exists := ci.pipelines[pipelineID]
	ci.mutex.RUnlock()

	if !exists {
		return fmt.Errorf("pipeline not found: %s", pipelineID)
	}

	fmt.Printf("è§¦å‘æµæ°´çº¿: %s\n", pipeline.Name)

	// æ‰§è¡Œæµæ°´çº¿é˜¶æ®µ
	for _, stage := range pipeline.Stages {
		if err := ci.executeStage(stage, context); err != nil {
			fmt.Printf("é˜¶æ®µ %s æ‰§è¡Œå¤±è´¥: %v\n", stage.Name, err)
			return err
		}
	}

	fmt.Printf("æµæ°´çº¿ %s æ‰§è¡Œå®Œæˆ\n", pipeline.Name)
	return nil
}

func (ci *CICDIntegrator) executeStage(stage PipelineStage, context map[string]interface{}) error {
	fmt.Printf("æ‰§è¡Œé˜¶æ®µ: %s (ç±»å‹: %v)\n", stage.Name, stage.Type)

	switch stage.Type {
	case PerformanceStage:
		return ci.executePerformanceStage(stage, context)
	case TestStage:
		return ci.executeTestStage(stage, context)
	default:
		fmt.Printf("è·³è¿‡é˜¶æ®µ: %s\n", stage.Name)
		return nil
	}
}

func (ci *CICDIntegrator) executePerformanceStage(stage PipelineStage, context map[string]interface{}) error {
	fmt.Printf("æ‰§è¡Œæ€§èƒ½æµ‹è¯•é˜¶æ®µ: %s\n", stage.Name)

	// æ‰§è¡Œæ€§èƒ½æµ‹è¯•
	for _, testID := range stage.Tests {
		fmt.Printf("è¿è¡Œæ€§èƒ½æµ‹è¯•: %s\n", testID)
		// å®é™…ä¼šè°ƒç”¨æ€§èƒ½æµ‹è¯•æ¡†æ¶
		time.Sleep(time.Millisecond * 100) // æ¨¡æ‹Ÿæµ‹è¯•æ‰§è¡Œ
	}

	// æ£€æŸ¥è´¨é‡é—¨ç¦
	return ci.checkQualityGates(context)
}

func (ci *CICDIntegrator) executeTestStage(stage PipelineStage, context map[string]interface{}) error {
	fmt.Printf("æ‰§è¡Œæµ‹è¯•é˜¶æ®µ: %s\n", stage.Name)

	for _, testID := range stage.Tests {
		fmt.Printf("è¿è¡Œæµ‹è¯•: %s\n", testID)
		time.Sleep(time.Millisecond * 50) // æ¨¡æ‹Ÿæµ‹è¯•æ‰§è¡Œ
	}

	return nil
}

func (ci *CICDIntegrator) checkQualityGates(context map[string]interface{}) error {
	for _, gate := range ci.gates {
		fmt.Printf("æ£€æŸ¥è´¨é‡é—¨ç¦: %s\n", gate.Name)

		for _, condition := range gate.Conditions {
			// æ¨¡æ‹ŸæŒ‡æ ‡æ£€æŸ¥
			value := secureRandomFloat64() * 100
			passed := ci.evaluateCondition(condition, value)

			if !passed && condition.Required {
				if gate.Action == FailPipeline {
					return fmt.Errorf("è´¨é‡é—¨ç¦å¤±è´¥: %s", gate.Name)
				} else if gate.Action == WarnAndContinue {
					fmt.Printf("âš ï¸ è´¨é‡é—¨ç¦è­¦å‘Š: %s\n", gate.Name)
				}
			}
		}
	}

	return nil
}

func (ci *CICDIntegrator) evaluateCondition(condition GateCondition, value float64) bool {
	switch condition.Operator {
	case LessThan:
		return value < condition.Threshold
	case GreaterThan:
		return value > condition.Threshold
	default:
		return true
	}
}

func (ci *CICDIntegrator) SendWebhook(event WebhookEvent, data map[string]interface{}) {
	for _, webhook := range ci.webhooks {
		// æ£€æŸ¥äº‹ä»¶æ˜¯å¦åŒ¹é…
		matches := false
		for _, e := range webhook.Events {
			if e == event {
				matches = true
				break
			}
		}

		if matches {
			go ci.sendWebhookRequest(webhook, data)
		}
	}
}

func (ci *CICDIntegrator) sendWebhookRequest(webhook WebhookConfig, data map[string]interface{}) {
	fmt.Printf("å‘é€Webhookåˆ°: %s\n", webhook.URL)
	// å®é™…ä¼šå‘é€HTTPè¯·æ±‚
}

// ==================
// 8. ä¸»æ¼”ç¤ºå‡½æ•°
// ==================

func demonstratePerformanceTestingFramework() {
	fmt.Println("=== Goè‡ªåŠ¨åŒ–æ€§èƒ½æµ‹è¯•æ¡†æ¶æ¼”ç¤º ===")

	// 1. åˆå§‹åŒ–æ¡†æ¶
	fmt.Println("\n1. åˆå§‹åŒ–æ€§èƒ½æµ‹è¯•æ¡†æ¶")
	config := FrameworkConfig{
		MaxConcurrentTests: 4,
		TestTimeout:        time.Minute * 5,
		RetentionPeriod:    time.Hour * 24,
		ReportInterval:     time.Hour,
		AlertThresholds: map[string]float64{
			"response_time": 500.0,
			"error_rate":    5.0,
			"throughput":    100.0,
		},
		CICDIntegration: true,
	}

	framework := NewPerformanceTestFramework(config)
	framework.Start()
	defer framework.Stop()

	// 2. åˆ›å»ºæµ‹è¯•å¥—ä»¶
	fmt.Println("\n2. åˆ›å»ºæ€§èƒ½æµ‹è¯•å¥—ä»¶")

	// åˆ›å»ºåŸºå‡†æµ‹è¯•
	benchmarkTest := &PerformanceTest{
		ID:   "bench_001",
		Name: "APIå“åº”æ—¶é—´åŸºå‡†æµ‹è¯•",
		Type: BenchmarkTest,
		Target: TestTarget{
			Function: func() error {
				time.Sleep(time.Millisecond * time.Duration(secureRandomInt(100)+50))
				if secureRandomFloat64() < 0.02 { // 2%é”™è¯¯ç‡
					return fmt.Errorf("æ¨¡æ‹Ÿé”™è¯¯")
				}
				return nil
			},
		},
		Configuration: TestConfiguration{
			Iterations:  1000,
			Concurrency: 10,
			WarmupRuns:  3,
			Timeout:     time.Second * 10,
		},
		Assertions: []PerformanceAssertion{
			{
				Metric:    "response_time_p95",
				Operator:  LessThan,
				Expected:  200.0,
				Tolerance: 10.0,
				Critical:  true,
			},
			{
				Metric:   "error_rate",
				Operator: LessThan,
				Expected: 5.0,
				Critical: true,
			},
		},
		Enabled: true,
	}

	// åˆ›å»ºè´Ÿè½½æµ‹è¯•
	loadTest := &PerformanceTest{
		ID:   "load_001",
		Name: "ç”¨æˆ·å¹¶å‘è´Ÿè½½æµ‹è¯•",
		Type: LoadTest,
		Target: TestTarget{
			Function: func() error {
				time.Sleep(time.Millisecond * time.Duration(secureRandomInt(200)+100))
				return nil
			},
		},
		Configuration: TestConfiguration{
			Duration:    time.Second * 30,
			Concurrency: 20,
			ThinkTime:   time.Millisecond * 100,
		},
		Enabled: true,
	}

	// åˆ›å»ºå‹åŠ›æµ‹è¯•
	stressTest := &PerformanceTest{
		ID:   "stress_001",
		Name: "ç³»ç»Ÿæé™å‹åŠ›æµ‹è¯•",
		Type: StressTest,
		Target: TestTarget{
			Function: func() error {
				time.Sleep(time.Millisecond * time.Duration(secureRandomInt(300)+50))
				if secureRandomFloat64() < 0.05 { // 5%é”™è¯¯ç‡
					return fmt.Errorf("å‹åŠ›æµ‹è¯•é”™è¯¯")
				}
				return nil
			},
		},
		Configuration: TestConfiguration{
			Duration:    time.Second * 20,
			Concurrency: 50,
		},
		Enabled: true,
	}

	// åˆ›å»ºæµ‹è¯•å¥—ä»¶
	testSuite := &TestSuite{
		Name:        "APIæ€§èƒ½æµ‹è¯•å¥—ä»¶",
		Description: "å…¨é¢çš„APIæ€§èƒ½æµ‹è¯•",
		Tests:       []*PerformanceTest{benchmarkTest, loadTest, stressTest},
		Environment: "staging",
		Schedule: TestSchedule{
			Type:     Periodic,
			Interval: time.Hour,
			Enabled:  true,
		},
		Enabled: true,
	}

	framework.RegisterTestSuite(testSuite)

	// 3. é…ç½®å‘Šè­¦è§„åˆ™
	fmt.Println("\n3. é…ç½®æ€§èƒ½å‘Šè­¦è§„åˆ™")

	alertManager := framework.alertManager

	// å“åº”æ—¶é—´å‘Šè­¦
	responseTimeRule := AlertRule{
		ID:        "response_time_alert",
		Name:      "å“åº”æ—¶é—´è¿‡é«˜å‘Šè­¦",
		Query:     "response_time_p95",
		Condition: AlertGreaterThan,
		Threshold: 500.0,
		Duration:  time.Minute * 2,
		Severity:  SeverityWarning,
		Labels:    map[string]string{"service": "api"},
		Annotations: map[string]string{
			"description": "API P95å“åº”æ—¶é—´è¶…è¿‡500ms",
			"runbook":     "https://wiki.company.com/runbooks/high-latency",
		},
		Enabled: true,
	}

	// é”™è¯¯ç‡å‘Šè­¦
	errorRateRule := AlertRule{
		ID:        "error_rate_alert",
		Name:      "é”™è¯¯ç‡è¿‡é«˜å‘Šè­¦",
		Query:     "error_rate",
		Condition: AlertGreaterThan,
		Threshold: 5.0,
		Duration:  time.Minute,
		Severity:  SeverityCritical,
		Labels:    map[string]string{"service": "api"},
		Annotations: map[string]string{
			"description": "APIé”™è¯¯ç‡è¶…è¿‡5%",
		},
		Enabled: true,
	}

	alertManager.AddRule(responseTimeRule)
	alertManager.AddRule(errorRateRule)

	// æ·»åŠ å‘Šè­¦é€šé“
	alertManager.AddChannel(&ConsoleAlertChannel{})

	// 4. è¿è¡Œæµ‹è¯•
	fmt.Println("\n4. æ‰§è¡Œæ€§èƒ½æµ‹è¯•")

	// æ‰‹åŠ¨è§¦å‘æµ‹è¯•æ‰§è¡Œ
	executor := framework.scheduler.executor

	fmt.Println("æ‰§è¡ŒåŸºå‡†æµ‹è¯•...")
	benchExecution := executor.Execute(benchmarkTest)
	time.Sleep(time.Second * 3) // ç­‰å¾…æ‰§è¡Œå®Œæˆ

	fmt.Println("æ‰§è¡Œè´Ÿè½½æµ‹è¯•...")
	loadExecution := executor.Execute(loadTest)
	time.Sleep(time.Second * 3)

	fmt.Println("æ‰§è¡Œå‹åŠ›æµ‹è¯•...")
	stressExecution := executor.Execute(stressTest)
	time.Sleep(time.Second * 3)

	// 5. ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
	fmt.Println("\n5. ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š")

	reporter := framework.reporter
	executions := []*TestExecution{benchExecution, loadExecution, stressExecution}

	reportPeriod := ReportPeriod{
		StartTime: time.Now().Add(-time.Hour),
		EndTime:   time.Now(),
		Duration:  time.Hour,
		Type:      Custom,
	}

	report := reporter.GenerateReport(executions, reportPeriod)

	// å¯¼å‡ºHTMLæŠ¥å‘Š
	htmlReport, err := reporter.ExportReport(report.ID, HTMLFormat)
	if err != nil {
		fmt.Printf("å¯¼å‡ºHTMLæŠ¥å‘Šå¤±è´¥: %v\n", err)
	} else {
		// ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
		reportPath := fmt.Sprintf("performance_report_%s.html", time.Now().Format("20060102_150405"))
		// G301/G306å®‰å…¨ä¿®å¤ï¼šä½¿ç”¨å®‰å…¨æƒé™å†™å…¥æŠ¥å‘Šæ–‡ä»¶
		if err := security.SecureWriteFile(reportPath, htmlReport, &security.SecureFileOptions{
			Mode:      security.GetRecommendedMode("data"),
			CreateDir: false,
		}); err != nil {
			fmt.Printf("ä¿å­˜æŠ¥å‘Šå¤±è´¥: %v\n", err)
		} else {
			fmt.Printf("æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: %s\n", reportPath)
		}
	}

	// 6. CI/CDé›†æˆæ¼”ç¤º
	fmt.Println("\n6. CI/CDé›†æˆæ¼”ç¤º")

	cicdIntegrator := framework.cicdIntegrator

	// åˆ›å»ºæ€§èƒ½æµ‹è¯•æµæ°´çº¿
	pipeline := &Pipeline{
		ID:   "perf_pipeline_001",
		Name: "æ€§èƒ½æµ‹è¯•æµæ°´çº¿",
		Stages: []PipelineStage{
			{
				Name:    "æ€§èƒ½æµ‹è¯•",
				Type:    PerformanceStage,
				Tests:   []string{"bench_001", "load_001"},
				Timeout: time.Minute * 10,
			},
		},
		Status: PipelinePending,
	}

	cicdIntegrator.RegisterPipeline(pipeline)

	// é…ç½®è´¨é‡é—¨ç¦
	qualityGate := QualityGate{
		Name: "æ€§èƒ½è´¨é‡é—¨ç¦",
		Conditions: []GateCondition{
			{
				Metric:    "response_time_p95",
				Operator:  LessThan,
				Threshold: 300.0,
				Required:  true,
			},
			{
				Metric:    "error_rate",
				Operator:  LessThan,
				Threshold: 2.0,
				Required:  true,
			},
		},
		Action: WarnAndContinue,
	}

	cicdIntegrator.gates = append(cicdIntegrator.gates, qualityGate)

	// è§¦å‘æµæ°´çº¿
	context := map[string]interface{}{
		"git_commit": "abc123",
		"branch":     "main",
		"build_id":   "build_456",
	}

	if err := cicdIntegrator.TriggerPipeline(pipeline.ID, context); err != nil {
		fmt.Printf("æµæ°´çº¿æ‰§è¡Œå¤±è´¥: %v\n", err)
	}

	// 7. æŒ‡æ ‡æ”¶é›†æ¼”ç¤º
	fmt.Println("\n7. æ€§èƒ½æŒ‡æ ‡æ”¶é›†æ¼”ç¤º")

	collector := framework.dataCollector

	// æ¨¡æ‹Ÿè®°å½•ä¸€äº›æ€§èƒ½æŒ‡æ ‡
	now := time.Now()
	collector.RecordMetric("api_response_time", 150.0, map[string]string{"endpoint": "/users"}, now)
	collector.RecordMetric("api_response_time", 200.0, map[string]string{"endpoint": "/orders"}, now)
	collector.RecordMetric("api_throughput", 1200.0, map[string]string{"service": "api"}, now)
	collector.RecordMetric("error_count", 5.0, map[string]string{"service": "api"}, now)

	// ç­‰å¾…èšåˆ
	time.Sleep(time.Second * 2)

	// è·å–èšåˆæŒ‡æ ‡
	throughputMetric := collector.GetAggregatedMetric("api_throughput", map[string]string{"service": "api"})
	if throughputMetric != nil {
		fmt.Printf("APIååé‡æŒ‡æ ‡: å¹³å‡=%.2f, æœ€å¤§=%.2f, P95=%.2f\n",
			throughputMetric.Mean, throughputMetric.Max, throughputMetric.P95)
	}

	// 8. æ€§èƒ½å¯¹æ¯”åˆ†æ
	fmt.Println("\n8. æ€§èƒ½å¯¹æ¯”åˆ†æ")
	demonstratePerformanceComparison()

	// 9. æ€»ç»“ç»Ÿè®¡
	fmt.Println("\n=== æ€§èƒ½æµ‹è¯•æ¡†æ¶ç»Ÿè®¡ ===")
	fmt.Printf("æ³¨å†Œçš„æµ‹è¯•å¥—ä»¶: 1\n")
	fmt.Printf("æ‰§è¡Œçš„æµ‹è¯•: %d\n", len(executions))
	fmt.Printf("ç”Ÿæˆçš„æŠ¥å‘Š: 1\n")
	fmt.Printf("é…ç½®çš„å‘Šè­¦è§„åˆ™: 2\n")
	fmt.Printf("CI/CDæµæ°´çº¿: 1\n")
}

func demonstratePerformanceComparison() {
	// æ¨¡æ‹Ÿæ€§èƒ½å¯¹æ¯”åˆ†æ
	fmt.Println("æ€§èƒ½å¯¹æ¯”åˆ†æ:")

	// åŸºçº¿æ•°æ®
	baselineMetrics := map[string]float64{
		"response_time_p95": 180.0,
		"throughput":        1000.0,
		"error_rate":        1.5,
		"cpu_usage":         65.0,
	}

	// å½“å‰æ•°æ®
	currentMetrics := map[string]float64{
		"response_time_p95": 150.0,
		"throughput":        1200.0,
		"error_rate":        1.0,
		"cpu_usage":         70.0,
	}

	fmt.Println("æŒ‡æ ‡å¯¹æ¯”:")
	for metric, baseline := range baselineMetrics {
		current := currentMetrics[metric]
		change := (current - baseline) / baseline * 100

		status := "ğŸ“ˆ"
		if metric == "response_time_p95" || metric == "error_rate" || metric == "cpu_usage" {
			if change < 0 {
				status = "âœ… æ”¹å–„"
			} else {
				status = "âš ï¸ ä¸‹é™"
			}
		} else {
			if change > 0 {
				status = "âœ… æ”¹å–„"
			} else {
				status = "âš ï¸ ä¸‹é™"
			}
		}

		fmt.Printf("  %s: %.2f -> %.2f (å˜åŒ–: %+.1f%%) %s\n",
			metric, baseline, current, change, status)
	}
}

// ==================
// 9. è¾…åŠ©å‡½æ•°å’Œç±»å‹
// ==================

// ConsoleAlertChannel æ§åˆ¶å°å‘Šè­¦é€šé“
type ConsoleAlertChannel struct{}

func (cac *ConsoleAlertChannel) SendAlert(alert *Alert) error {
	fmt.Printf("ğŸš¨ [%v] %s: %s (å€¼: %.2f, é˜ˆå€¼: %.2f)\n",
		alert.Severity, alert.Name, alert.Annotations["description"], alert.Value, alert.Threshold)
	return nil
}

func (cac *ConsoleAlertChannel) Name() string {
	return "console"
}

func generateExecutionID() string {
	return fmt.Sprintf("exec_%d_%d", time.Now().Unix(), secureRandomInt(10000))
}

func generateReportID() string {
	return fmt.Sprintf("report_%d", time.Now().Unix())
}

func generateAlertID() string {
	return fmt.Sprintf("alert_%d_%d", time.Now().Unix(), secureRandomInt(10000))
}

func main() {
	demonstratePerformanceTestingFramework()

	fmt.Println("\n=== Goè‡ªåŠ¨åŒ–æ€§èƒ½æµ‹è¯•æ¡†æ¶æ¼”ç¤ºå®Œæˆ ===")
	fmt.Println("\nå­¦ä¹ è¦ç‚¹æ€»ç»“:")
	fmt.Println("1. æµ‹è¯•æ¡†æ¶ï¼šå®Œæ•´çš„ä¼ä¸šçº§æ€§èƒ½æµ‹è¯•ä½“ç³»æ¶æ„")
	fmt.Println("2. æµ‹è¯•ç±»å‹ï¼šåŸºå‡†ã€è´Ÿè½½ã€å‹åŠ›ã€å°–å³°ã€æŒä¹…æ€§ç­‰æµ‹è¯•")
	fmt.Println("3. è‡ªåŠ¨è°ƒåº¦ï¼šåŸºäºæ—¶é—´ã€äº‹ä»¶ã€æ¡ä»¶çš„æ™ºèƒ½æµ‹è¯•è°ƒåº¦")
	fmt.Println("4. ç»“æœåˆ†æï¼šå¤šç»´åº¦æ€§èƒ½æŒ‡æ ‡æ”¶é›†å’Œç»Ÿè®¡åˆ†æ")
	fmt.Println("5. æŠ¥å‘Šç”Ÿæˆï¼šå¯è§†åŒ–æ€§èƒ½æŠ¥å‘Šå’Œè¶‹åŠ¿åˆ†æ")
	fmt.Println("6. å‘Šè­¦ç®¡ç†ï¼šæ™ºèƒ½åŒ–æ€§èƒ½å¼‚å¸¸æ£€æµ‹å’Œé€šçŸ¥")
	fmt.Println("7. CI/CDé›†æˆï¼šæ— ç¼é›†æˆåˆ°DevOpsæµæ°´çº¿")
	fmt.Println("8. è´¨é‡é—¨ç¦ï¼šåŸºäºæ€§èƒ½æŒ‡æ ‡çš„å‘å¸ƒè´¨é‡æ§åˆ¶")

	fmt.Println("\nä¼ä¸šçº§ç‰¹æ€§:")
	fmt.Println("- åˆ†å¸ƒå¼æµ‹è¯•æ‰§è¡Œå’Œç»“æœèšåˆ")
	fmt.Println("- å¤šç¯å¢ƒæ€§èƒ½å¯¹æ¯”å’ŒåŸºçº¿ç®¡ç†")
	fmt.Println("- è‡ªé€‚åº”æ€§èƒ½é˜ˆå€¼å’Œæ™ºèƒ½å‘Šè­¦")
	fmt.Println("- æ€§èƒ½è¶‹åŠ¿é¢„æµ‹å’Œå®¹é‡è§„åˆ’")
	fmt.Println("- å¤šæ ¼å¼æŠ¥å‘Šå¯¼å‡ºå’Œä»ªè¡¨æ¿")
	fmt.Println("- ä¸ç›‘æ§ç³»ç»Ÿçš„æ·±åº¦é›†æˆ")
	fmt.Println("- æ€§èƒ½æ•°æ®çš„é•¿æœŸå­˜å‚¨å’Œåˆ†æ")
}

/*
=== ç»ƒä¹ é¢˜ ===

1. æ¡†æ¶æ‰©å±•ï¼š
   - å®ç°æ›´å¤šæµ‹è¯•ç±»å‹ï¼ˆå®¹é‡æµ‹è¯•ã€å¯é æ€§æµ‹è¯•ï¼‰
   - æ·»åŠ å®æ—¶æ€§èƒ½ç›‘æ§åŠŸèƒ½
   - å®ç°åˆ†å¸ƒå¼æµ‹è¯•æ‰§è¡Œ
   - åˆ›å»ºæ€§èƒ½æµ‹è¯•DSL

2. é«˜çº§åˆ†æï¼š
   - å®ç°æ€§èƒ½è¶‹åŠ¿é¢„æµ‹ç®—æ³•
   - æ·»åŠ å¼‚å¸¸æ£€æµ‹å’Œæ ¹å› åˆ†æ
   - åˆ›å»ºæ€§èƒ½åŸºçº¿è‡ªåŠ¨æ›´æ–°æœºåˆ¶
   - å®ç°å¤šç»´åº¦æ€§èƒ½å¯¹æ¯”

3. CI/CDæ·±åº¦é›†æˆï¼š
   - å®ç°Gité’©å­è§¦å‘çš„æ€§èƒ½æµ‹è¯•
   - æ·»åŠ æ€§èƒ½å›å½’è‡ªåŠ¨é˜»æ–­
   - åˆ›å»ºæ€§èƒ½é¢„ç®—ç®¡ç†ç³»ç»Ÿ
   - å®ç°è“ç»¿éƒ¨ç½²æ€§èƒ½éªŒè¯

4. ä¼ä¸šçº§åŠŸèƒ½ï¼š
   - å®ç°å¤šç§Ÿæˆ·æ€§èƒ½æµ‹è¯•éš”ç¦»
   - æ·»åŠ æˆæœ¬ç®¡æ§å’Œèµ„æºä¼˜åŒ–
   - åˆ›å»ºæ€§èƒ½æµ‹è¯•æ²»ç†ä½“ç³»
   - å®ç°æ€§èƒ½æµ‹è¯•æ ‡å‡†åŒ–

5. å¯è§‚æµ‹æ€§å¢å¼ºï¼š
   - é›†æˆAPMç³»ç»Ÿæ•°æ®
   - å®ç°å®æ—¶æ€§èƒ½æŒ‡æ ‡æµ
   - åˆ›å»ºæ€§èƒ½å¼‚å¸¸è”åˆåˆ†æ
   - æ·»åŠ ä¸šåŠ¡æŒ‡æ ‡å…³è”åˆ†æ

å·¥å…·é›†æˆï¼š
- JMeter/Gatling è´Ÿè½½æµ‹è¯•å·¥å…·
- Grafana æ€§èƒ½æ•°æ®å¯è§†åŒ–
- Prometheus æŒ‡æ ‡æ”¶é›†å­˜å‚¨
- Jenkins/GitLab CI æµæ°´çº¿é›†æˆ
- Kubernetes å®¹å™¨åŒ–æµ‹è¯•ç¯å¢ƒ

é‡è¦æ¦‚å¿µï¼š
- Performance Testing: ç³»ç»ŸåŒ–æ€§èƒ½æµ‹è¯•æ–¹æ³•
- Load Testing: è´Ÿè½½æµ‹è¯•å’Œå®¹é‡è§„åˆ’
- Stress Testing: æé™å‹åŠ›å’Œæ•…éšœæ¢å¤
- Quality Gates: æ€§èƒ½è´¨é‡é—¨ç¦æ§åˆ¶
- SLI/SLO: æœåŠ¡ç­‰çº§æŒ‡æ ‡å’Œç›®æ ‡
- Performance Budget: æ€§èƒ½é¢„ç®—ç®¡ç†
- Shift-Left Testing: æ€§èƒ½æµ‹è¯•å·¦ç§»
*/
